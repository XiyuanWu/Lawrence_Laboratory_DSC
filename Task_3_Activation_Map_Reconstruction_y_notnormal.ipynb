{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7f46fd54",
   "metadata": {},
   "source": [
    "# Task 3 Activation Map Reconstruction\n",
    "\n",
    "\n",
    "## PLAN\n",
    "\n",
    "### 1.1 Dataset Instruction\n",
    "\n",
    "Download the dataset from the [Dataset of Simulated Intracardiac Transmembrane Voltage Recordings and ECG Signals](https://library.ucsd.edu/dc/object/bb29449106) by running following command: \n",
    "\n",
    "```bash\n",
    "source download_intracardiac_dataset.sh\n",
    "```\n",
    "\n",
    "### 1.2 Task Description\n",
    "\n",
    "*Understand the time when each part of the heart is activated.*\n",
    "\n",
    "The objective is to build a model that can predict the activation times at the 75 myocardial points based on the ECG data from the 12 leads."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "76de3016",
   "metadata": {},
   "source": [
    "### 1.3 Load Modules and Preprocessing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf9c735c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analysis\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import glob, re, os\n",
    "from typing import List\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Modeling\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# # Evaluate\n",
    "# from sklearn.metrics import mean_absolute_error\n",
    "# from sklearn.metrics import mean_squared_error\n",
    "# from sklearn.metrics import r2_score\n",
    "\n",
    "# Data processing\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "# Save model\n",
    "import pickle\n",
    "\n",
    "# Ignore warning\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "pd.set_option(\"display.max_rows\", 100)\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "75d37977",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the cardiac_ml_tools.py script\n",
    "%run ./cardiac_challenge/notebooks/cardiac_ml_tools.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c4eb774",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of file pairs: 16117\n",
      "Example of file pair:\n",
      "./cardiac_challenge/intracardiac_dataset/data_hearts_dd_0p2_geo_inn_act_3_bcl/pECGData_hearts_dd_0p2_geo_inn_act_3_bcl_bcl.1000.innerindex.0.volunteer.v13.npy\n",
      "./cardiac_challenge/intracardiac_dataset/data_hearts_dd_0p2_geo_inn_act_3_bcl/VmData_hearts_dd_0p2_geo_inn_act_3_bcl_bcl.1000.innerindex.0.volunteer.v13.npy\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "data_dirs = []\n",
    "regex = r'data_hearts_dd_0p2*'\n",
    "DIR = './cardiac_challenge/intracardiac_dataset/' # path to the intracardiac_dataset\n",
    "\n",
    "for x in os.listdir(DIR):\n",
    "    if re.match(regex, x):\n",
    "        data_dirs.append(DIR + x)\n",
    "file_pairs = read_data_dirs(data_dirs)\n",
    "print('Number of file pairs: {}'.format(len(file_pairs)))\n",
    "# example of file pair\n",
    "print(\"Example of file pair:\")\n",
    "print(\"{}\\n{}\".format(file_pairs[0][0], file_pairs[0][1]))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "19bb1412",
   "metadata": {},
   "source": [
    "### 1.4 Dataset details\n",
    "\n",
    "\n",
    "The dataset [Dataset of Simulated Intracardiac Transmembrane Voltage Recordings and ECG Signals](https://library.ucsd.edu/dc/object/bb29449106) \n",
    "consists of pairs of computationally simulated intracardiac transmembrane voltage recordings and ECG signals.\n",
    "In total, 16140 organ-level simulations were conducted to create this dataset.\n",
    "Simulations were performed using Lassen supercomputer at Lawrence Livermore National Lab (LLNL), concurrently utilizing 4 GPUs and 40 CPU cores.\n",
    "Each simulation produced pairs of 500ms-by-10 raw electrode signals and 500ms-by-75 transmembrane voltage signals.\n",
    "For convenience, we collect those signals in matrices and give them the following names:\n",
    "\n",
    "Tensor | Description | Shape | Notes\n",
    "--- | --- | --- | ---\n",
    "$X$ | Row electrode signals | $10 \\times 500$ | 10-lead ECG signals from the simulated torso (in [Dataset of Simulated Intracardiac Transmembrane Voltage Recordings and ECG Signals](https://library.ucsd.edu/dc/object/bb29449106))\n",
    "$V$ | Activation map | $75 \\times 500$ | Transmembrane voltage signals from the simulated heart (in [Dataset of Simulated Intracardiac Transmembrane Voltage Recordings and ECG Signals](https://library.ucsd.edu/dc/object/bb29449106))\n",
    "$E$ | 12-lead ECG signals | $12 \\times 500$ | 12-lead ECG signals obtained by `get_standard_leads`($X$)\n",
    "$A$ | Activation map | $75 \\times 1$ | Activation time, defined as $A_i = \\text{min}_j(V_{ij})$\n",
    "\n",
    "**IMPORTANT** : The raw data in the dataset consists of 10-lead ECG signals and 75-lead transmembrane voltage signals. The 12-lead ECG signals are obtained from the 10-lead ECG signals using the function `get_standard_leads` (in the file `cardiac_ml_tools.py`).\n",
    "\n",
    "The overall generation process is shown in the following image. The ECG signal is recorded using 10 virtual electrodes and the transmembrane voltages are recorded at 75 points within the myocardium. The transmembrane voltages are then used to generate the spatio-temporal activation maps."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b7ac66a2",
   "metadata": {},
   "source": [
    "![if picture not show, see path \"/cardiac_challenge/figures/data_generation.png\"](./cardiac_challenge/figures/data_generation.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "66018f88",
   "metadata": {},
   "source": [
    "## ANALYZE\n",
    "\n",
    "### 2.1 Getting the standard 12-lead ECG from the 10-lead ECG\n",
    "\n",
    "The function `get_standard_leads` (in the file `cardiac_ml_tools.py`) is used to obtain the 12-lead ECG signals from the 10-lead ECG signals. It implements the following transformation, where the (Wilson Lead) is defined as $Vw = 1/3*(RA + LA + LL)$:\n",
    "$$\n",
    "\\left\\{\n",
    "\\begin{array}{lll}\n",
    "    X_{:,1}  & \\to  & RA \\\\\n",
    "    X_{:,2}  & \\to  & LA \\\\\n",
    "    X_{:,3}  & \\to  & LL \\\\\n",
    "    X_{:,4}  & \\to  & RL \\\\\n",
    "    X_{:,5}  & \\to  & V1 \\\\\n",
    "    X_{:,6}  & \\to  & V2 \\\\\n",
    "    X_{:,7}  & \\to  & V3 \\\\\n",
    "    X_{:,8}  & \\to  & V4 \\\\\n",
    "    X_{:,9}  & \\to  & V5 \\\\\n",
    "    X_{:,10} & \\to &  V6 \\\\\n",
    "\\end{array}\n",
    "\\right.\n",
    "\\text{        and        }\n",
    "\\left\\{\n",
    "\\begin{array}{lll}          \n",
    "\\text{Lead } I& : & LA - RA \\\\\n",
    "\\text{Lead } II& : & LL - RA \\\\\n",
    "\\text{Lead } III& : & LL - LA \\\\\n",
    "\\text{Lead } aVR& : &  \\frac{3}{2} (RA - Vw) \\\\\n",
    "\\text{Lead } aVL& : &  \\frac{3}{2} (LA - Vw) \\\\\n",
    "\\text{Lead } aVF& : &  \\frac{3}{2} (LL - Vw)\\\\ \n",
    "\\text{Lead } V1 & : & V1 - Vw \\\\\n",
    "\\text{Lead } V2 & : & V2 - Vw \\\\\n",
    "\\text{Lead } V3 & : & V3 - Vw \\\\\n",
    "\\text{Lead } V4 & : & V4 - Vw \\\\\n",
    "\\text{Lead } V5 & : & V5 - Vw \\\\\n",
    "\\text{Lead } V6 & : & V6 - Vw \\\\\n",
    "\\end{array}\n",
    "\\right.\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc3bed18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Example of file pair\n",
    "# case = 213\n",
    "# # ECG plot\n",
    "# row = 3 \n",
    "# column = 4\n",
    "# num_timesteps = 500\n",
    "# plt.figure(figsize=(10, 7))\n",
    "# titles = [\"I\", \"II\", \"III\", \"aVR\", \"aVL\", \"aVF\", \"V1\", \"V2\", \"V3\", \"V4\", \"V5\", \"V6\"]\n",
    "# reorder = {1:1,2:5,3:9,4:2,5:6,6:10,7:3,8:7,9:11,10:4,11:8,12:12} # reorder the leads to standard 12-lead ECG display\n",
    "\n",
    "# print('Case {} : {}'.format(case, file_pairs[case][0]))\n",
    "# pECGData = np.load(file_pairs[case][0])\n",
    "# pECGData = get_standard_leads(pECGData)\n",
    "\n",
    "# # create a figure with 12 subplots\n",
    "# for i in range(pECGData.shape[1]):\n",
    "#     plt.subplot(row, column, reorder[i + 1])\n",
    "#     plt.plot(pECGData[0:num_timesteps,i],'r', color='blue', alpha=0.8)\n",
    "#     plt.title(titles[i])\n",
    "#     # plt.plot(visible=True, color='blue', linestyle='-')\n",
    "#     plt.minorticks_on()\n",
    "#     # plt.plot(visible=True, color='blue', linestyle='-', alpha=0.2)\n",
    "#     plt.xlabel('msec')\n",
    "#     plt.ylabel('mV')\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n",
    "# # close\n",
    "# plt.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7346c1bb",
   "metadata": {},
   "source": [
    "### 2.2 Getting the activation map from the transmembrane voltages\n",
    "\n",
    "The funtion `get_activation_map` (in the file `cardiac_ml_tools.py`) is used to obtain the activation map from the transmembrane voltages. It implements the following transformation $A_i = \\text{min}_j(V_{ij})$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee45c6de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Example of file pair\n",
    "# case = 213\n",
    "# # plt.figure(figsize=(1, 10))\n",
    "# plt.figure(figsize=(15, 2))\n",
    "\n",
    "# print('Case {} : {}'.format(case, file_pairs[case][0]))\n",
    "# VmData = np.load(file_pairs[case][1])\n",
    "\n",
    "# ActTime = get_activation_time(VmData)\n",
    "\n",
    "# # plot the Activation Time array\n",
    "# plt.imshow(ActTime.T, cmap='jet', interpolation='nearest', aspect='auto')\n",
    "# plt.title('Activation Time')\n",
    "# plt.colorbar()\n",
    "# plt.grid(visible=True, which='major', color='#666666', linestyle='-')\n",
    "# plt.minorticks_on()\n",
    "# # not yticks\n",
    "# plt.yticks([])\n",
    "# plt.grid(visible=True, which='minor', color='#999999', linestyle='-', alpha=0.2)\n",
    "# plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c0123209",
   "metadata": {},
   "source": [
    "### 3.3 Learning the mapping from the 12-lead ECG to the activation map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c1b6d72c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # make a plot with the \"pECGData\" -> \"ActTime\"\n",
    "# case = 213\n",
    "\n",
    "# print('Case {} : {}'.format(case, file_pairs[case][0]))\n",
    "# pECGData = np.load(file_pairs[case][0])\n",
    "# pECGData = get_standard_leads(pECGData)\n",
    "\n",
    "# print('Case {} : {}'.format(case, file_pairs[case][0]))\n",
    "# VmData = np.load(file_pairs[case][1])\n",
    "# ActTime = get_activation_time(VmData)\n",
    "\n",
    "# # plot in row the tensors pECGData and ActTime with an arrow pointing to the activation time\n",
    "# row = 1\n",
    "# column = 3\n",
    "# plt.figure(figsize=(20, 5))\n",
    "# plt.subplot(row, column, 1)\n",
    "# # plot pECGData transposed\n",
    "# plt.imshow(pECGData.T, cmap='jet', interpolation='nearest', aspect='auto')\n",
    "# plt.title('pECGData')\n",
    "# plt.subplot(row, column, 2)\n",
    "# # print an arrow\n",
    "# plt.text(0.5, 0.5, '-------->', horizontalalignment='center', verticalalignment='center', fontsize=20)\n",
    "# plt.axis('off')\n",
    "# plt.subplot(row, column, 3)\n",
    "# # plot ActTime\n",
    "# plt.imshow(ActTime, cmap='jet', interpolation='nearest', aspect='auto')\n",
    "# # not xticks\n",
    "# plt.xticks([])\n",
    "# plt.title('ActTime')\n",
    "# plt.show()\n",
    "# plt.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "204d7bd1",
   "metadata": {},
   "source": [
    "**Tricks**\n",
    "\n",
    "As in many machine learning problems, normalization of the data might be helpful or even necessary. Different normalization schemes might be applied."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ffeee68",
   "metadata": {},
   "source": [
    "## CONSTRUCT\n",
    "\n",
    "**Model: 1D CNN**\n",
    "\n",
    "**Approach**\n",
    "\n",
    "We to flatten each 2D sample (12x500) from the ECG data into a 1D row, transforming each sample from a matrix into a long vector. Then, you want to stack all these vectors from over 16,000 samples into a single large dataset where each row represents one sample, fully flattened, resulting in a dataset with dimensions of (16000, 6000) — since 12 x 500 = 6000.\n",
    "\n",
    "Here’s the step-by-step plan to achieve this:\n",
    "\n",
    "1. **Flatten Each Sample**: Each 12x500 matrix will be reshaped into a single row of 6000 elements. This converts the 2D feature set of each sample into a 1D array.\n",
    "\n",
    "2. **Stack All Samples**: After flattening each sample, you'll stack them vertically to create a new dataset where each row corresponds to one of the original 2D samples, now represented as a long 1D vector.\n",
    "\n",
    "3. **Create a Uniform Dataset**: The result will be a large dataset where every sample is consistently formatted in a single row, making it easier to handle in terms of data processing and input into machine learning models.\n",
    "\n",
    "4. **Store or Process This Dataset**: Depending on the final application, this dataset can then be either stored for further use, processed for normalization, or directly used as input for machine learning models, particularly for tasks like clustering, classification, or regression.\n",
    "\n",
    "This approach effectively transforms a complex 2D dataset into a more manageable 1D format, albeit at the expense of increasing the dimensionality of each data point. This can be useful for certain types of analyses or machine learning models that require a flat vector per sample.\n",
    "\n",
    "**Combine Dataset Approach**\n",
    "\n",
    "Given that your full dataset contains over 16,000 samples, here's a graduated approach to determining an initial subset size:\n",
    "\n",
    "- **Initial Proof of Concept**: Start with a very small amount of data, perhaps around **100 to 500 samples**. This size is usually sufficient to ensure that your data loading, processing, and model training pipelines are functioning correctly without excessive computational overhead.\n",
    "\n",
    "- **Preliminary Testing**: Once your initial setup is verified to be working correctly, increase the size to about **1,000 to 2,000 samples**. This provides a more statistically significant dataset to start tuning hyperparameters and testing model performance while still being manageable in terms of computational resources and time.\n",
    "\n",
    "- **Detailed Testing and Validation**: If the model performs well on 1,000 to 2,000 samples, consider using a larger subset, such as **5,000 to 10,000 samples**, to further refine your model and prepare for full-scale training. This step is crucial for understanding how well the model scales with data size and for final adjustments before deploying the model on the entire dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca82414b",
   "metadata": {},
   "source": [
    "\n",
    "### 3.1 Data Processing\n",
    "\n",
    "#### 3.1.1 Combine Dataset\n",
    "\n",
    "In PyTorch, when dealing with 1D convolutional neural networks (CNNs), the data should be reshaped to follow the format `[batch_size, channels, length]`, where:\n",
    "\n",
    "- **batch_size** is the number of samples in a batch.\n",
    "- **channels** corresponds to the number of features per timestep, often equated with the number of sensors or measurement types in your dataset.\n",
    "- **length** is the number of timesteps per sample.\n",
    "\n",
    "In this case, we do `[num_samples, 12, 500]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8e32d1dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If file active.npy and ecg.npy are already created, load them\n",
    "if os.path.exists('./combine_dataset/ecg_data.npy') and os.path.exists('./combine_dataset/active_time.npy'):\n",
    "# if os.path.exists('./combine_dataset/ecg_data_5000.npy') and os.path.exists('./combine_dataset/active_time_5000.npy'):\n",
    "    ECGData = np.load('./combine_dataset/ecg_data.npy')\n",
    "    ActTime = np.load('./combine_dataset/active_time.npy')\n",
    "    # ECGData = np.load('./combine_dataset/ecg_data_5000.npy')\n",
    "    # ActTime = np.load('./combine_dataset/active_time_5000.npy')\n",
    "\n",
    "else:\n",
    "    # file_pairs is a list where each element is a tuple containing the file paths for ECG data and activation time data\n",
    "    num_samples = 16117  # Number of samples to process\n",
    "    # num_samples = 5000  # Number of samples to process\n",
    "    num_timesteps = 500  # Each ECG data has 500 timesteps\n",
    "    num_leads = 12  # Standard ECG leads count after processing\n",
    "\n",
    "    # Initialize arrays to store combined data\n",
    "    ECGData = np.zeros((num_samples, num_leads, num_timesteps))  # 3D array for ECG data\n",
    "    ActTime = np.zeros((num_samples, 75))  # Store 75 activation times per sample\n",
    "\n",
    "    # Process each sample\n",
    "    for i in range(num_samples):\n",
    "        # Load ECG data\n",
    "        pECGData = np.load(file_pairs[i][0])\n",
    "        pECGData = get_standard_leads(pECGData)  # Convert to 12 standard leads\n",
    "        ECGData[i, :, :] = pECGData.T  # Store in 3D array directly\n",
    "\n",
    "        # Load and process activation time data\n",
    "        VmData = np.load(file_pairs[i][1])\n",
    "        ActTime[i, :] = get_activation_time(VmData).flatten()  # Flatten the (75, 1) array to fit into (75,) array\n",
    "\n",
    "    # Create directory if it does not exist\n",
    "    output_dir = './combine_dataset'\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # Save combined datasets to .npy format\n",
    "    np.save(os.path.join(output_dir, 'ecg_data.npy'), ECGData)\n",
    "    np.save(os.path.join(output_dir, 'active_time.npy'), ActTime)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa015579",
   "metadata": {},
   "source": [
    "After combine, check them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0af15993",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ECGData shape: (16117, 12, 500)\n",
      "ActTime shape: (16117, 75)\n"
     ]
    }
   ],
   "source": [
    "print(\"ECGData shape: {}\".format(ECGData.shape))\n",
    "print(\"ActTime shape: {}\".format(ActTime.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38ad071c",
   "metadata": {},
   "source": [
    "\n",
    "#### 3.1.2 Split Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f4365507",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((12893, 12, 500),\n",
       " (12893, 75),\n",
       " (1612, 12, 500),\n",
       " (1612, 75),\n",
       " (1612, 12, 500),\n",
       " (1612, 75))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shuffle indices\n",
    "indices = np.arange(ECGData.shape[0])\n",
    "shuffled_indices = shuffle(indices, random_state=42)\n",
    "\n",
    "# Define the split ratios\n",
    "train_ratio = 0.8  # 80% training\n",
    "val_ratio = 0.1  # 10% validation\n",
    "test_ratio = 0.1  # 10% test\n",
    "\n",
    "# Calculate the split points\n",
    "train_split = int(len(shuffled_indices) * train_ratio)\n",
    "val_split = int(len(shuffled_indices) * (train_ratio + val_ratio))\n",
    "\n",
    "# Split indices into training, validation, and test sets\n",
    "train_indices = shuffled_indices[:train_split]\n",
    "val_indices = shuffled_indices[train_split:val_split]\n",
    "test_indices = shuffled_indices[val_split:]\n",
    "\n",
    "# Use indices to create training, validation, and test data\n",
    "x_train = ECGData[train_indices]\n",
    "y_train = ActTime[train_indices]\n",
    "x_val = ECGData[val_indices]\n",
    "y_val = ActTime[val_indices]\n",
    "x_test = ECGData[test_indices]\n",
    "y_test = ActTime[test_indices]\n",
    "\n",
    "# Print the shapes of the data\n",
    "x_train.shape, y_train.shape, x_val.shape, y_val.shape, x_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b105e24",
   "metadata": {},
   "source": [
    "#### 3.1.3 Normalize Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "30a2b38a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min values: [tensor(-5.9469), tensor(-5.5515), tensor(-3.5719), tensor(-4.2882), tensor(-4.2226), tensor(-3.1564), tensor(-2.4479), tensor(-2.3431), tensor(-2.5146), tensor(-2.3105), tensor(-1.9630), tensor(-2.3298)] \n",
      "Max values: [tensor(4.5094), tensor(4.2176), tensor(4.2389), tensor(5.4646), tensor(3.5553), tensor(3.0083), tensor(2.9844), tensor(2.3593), tensor(2.2054), tensor(2.0142), tensor(1.6994), tensor(2.1287)]\n",
      "Min values: [tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.)] \n",
      "Max values: [tensor(158.), tensor(162.), tensor(153.), tensor(147.), tensor(164.), tensor(165.), tensor(162.), tensor(163.), tensor(162.), tensor(149.), tensor(148.), tensor(147.), tensor(145.), tensor(152.), tensor(153.), tensor(150.), tensor(135.), tensor(139.), tensor(152.), tensor(156.), tensor(150.), tensor(158.), tensor(163.), tensor(164.), tensor(171.), tensor(176.), tensor(178.), tensor(162.), tensor(155.), tensor(173.), tensor(172.), tensor(167.), tensor(143.), tensor(152.), tensor(160.), tensor(170.), tensor(168.), tensor(156.), tensor(167.), tensor(157.), tensor(162.), tensor(163.), tensor(156.), tensor(170.), tensor(170.), tensor(163.), tensor(177.), tensor(168.), tensor(181.), tensor(170.), tensor(175.), tensor(169.), tensor(171.), tensor(167.), tensor(182.), tensor(185.), tensor(179.), tensor(172.), tensor(162.), tensor(169.), tensor(163.), tensor(150.), tensor(150.), tensor(150.), tensor(169.), tensor(170.), tensor(167.), tensor(164.), tensor(145.), tensor(163.), tensor(160.), tensor(155.), tensor(176.), tensor(171.), tensor(165.)]\n"
     ]
    }
   ],
   "source": [
    "# Convert numpy arrays to PyTorch tensors\n",
    "x_train_tensor = torch.tensor(x_train, dtype=torch.float32)\n",
    "x_val_tensor = torch.tensor(x_val, dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(x_test, dtype=torch.float32)\n",
    "\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32)\n",
    "y_val_tensor = torch.tensor(y_val, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.float32)\n",
    "\n",
    "# Calculate the min and max values and add to list\n",
    "x_min_list = []\n",
    "x_max_list = []\n",
    "y_min_list = []\n",
    "y_max_list = []\n",
    "\n",
    "for i in range(x_train_tensor.shape[1]): # loop 12 leads\n",
    "    min_value = x_train_tensor[:, i].min()\n",
    "    max_value = x_train_tensor[:, i].max()\n",
    "    x_min_list.append(min_value)\n",
    "    x_max_list.append(max_value)\n",
    "\n",
    "for i in range(y_train_tensor.shape[1]): # loop 75 activation times\n",
    "    min_value = y_train_tensor[:, i].min()\n",
    "    max_value = y_train_tensor[:, i].max()\n",
    "    y_min_list.append(min_value)\n",
    "    y_max_list.append(max_value)\n",
    "\n",
    "print(\"Min values:\", x_min_list, \"\\nMax values:\", x_max_list)\n",
    "print(\"Min values:\", y_min_list, \"\\nMax values:\", y_max_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f58fd456",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized training data shape: (12893, 12, 500)\n",
      "Normalized validation data shape: (1612, 12, 500)\n",
      "Normalized test data shape: (1612, 12, 500)\n"
     ]
    }
   ],
   "source": [
    "# Normalize the data\n",
    "def normalize_x(data, min_val, max_val):\n",
    "    # normalize_dataset = np.zeros(data.shape)\n",
    "    for i in range(data.shape[1]):\n",
    "        data[:, i] = np.divide(data[:, i], max_val[i])\n",
    "    return data\n",
    "\n",
    "# Normalize the datasets\n",
    "x_train_normalized = normalize_x(x_train, np.min(x_train), x_max_list)\n",
    "x_val_normalized = normalize_x(x_val, np.min(x_train), x_max_list)\n",
    "X_test_normalized = normalize_x(x_test, np.min(x_train), x_max_list)\n",
    "\n",
    "# y_train_normalized = np.divide((y_train - y_train.min()), (y_train.max() - min_value))\n",
    "# y_val_normalized = np.divide((y_val - y_train.min()), (y_train.max( )- min_value))\n",
    "# y_test_normalized = np.divide((y_test - y_train.min()), (y_train.max() - min_value))\n",
    "\n",
    "# You can print the shapes to verify the sizes are correct and the operations have been applied uniformly\n",
    "print(\"Normalized training data shape:\", x_train_normalized.shape)\n",
    "print(\"Normalized validation data shape:\", x_val_normalized.shape)\n",
    "print(\"Normalized test data shape:\", X_test_normalized.shape)\n",
    "# print(\"Normalized training labels shape:\", y_train_normalized.shape)\n",
    "# print(\"Normalized validation labels shape:\", y_val_normalized.shape)\n",
    "# print(\"Normalized test labels shape:\", y_test_normalized.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6b21c601",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # plot the 1 sample from x_train_normalized, 12 leads total\n",
    "# plt.figure(figsize=(10, 7))\n",
    "# titles = [\"I\", \"II\", \"III\", \"aVR\", \"aVL\", \"aVF\", \"V1\", \"V2\", \"V3\", \"V4\", \"V5\", \"V6\"]\n",
    "\n",
    "# for i in range(x_train.shape[1]):\n",
    "#     plt.subplot(3, 4, i + 1)\n",
    "#     plt.plot(x_train[10, i, :], color='blue', alpha=0.8)\n",
    "#     plt.title(titles[i])\n",
    "#     plt.minorticks_on()\n",
    "#     plt.xlabel('msec')\n",
    "#     plt.ylabel('mV')\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n",
    "# plt.close()\n",
    "\n",
    "\n",
    "# plt.figure(figsize=(10, 7))\n",
    "# # create a figure with 12 subplots\n",
    "# for i in range(x_train_normalized.shape[1]):\n",
    "#     plt.subplot(3, 4, i + 1)\n",
    "#     plt.plot(x_train_normalized[10, i, :], color='blue', alpha=0.8)\n",
    "#     plt.title(titles[i])\n",
    "#     plt.minorticks_on()\n",
    "#     plt.xlabel('msec')\n",
    "#     plt.ylabel('mV')\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n",
    "# plt.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1994339c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_batch shape: torch.Size([64, 12, 500])\n",
      "y_batch shape: torch.Size([64, 75])\n"
     ]
    }
   ],
   "source": [
    "# convery normalized to tensor\n",
    "x_train_normalized_tensor = torch.tensor(x_train_normalized, dtype=torch.float32)\n",
    "x_val_normalized_tensor = torch.tensor(x_val_normalized, dtype=torch.float32)\n",
    "X_test_normalized_tensor = torch.tensor(X_test_normalized, dtype=torch.float32)\n",
    "\n",
    "# y_train_normalized_tensor = torch.tensor(y_train_normalized, dtype=torch.float32)\n",
    "# y_val_normalized_tensor = torch.tensor(y_val_normalized, dtype=torch.float32)\n",
    "# y_test_normalized_tensor = torch.tensor(y_test_normalized, dtype=torch.float32)\n",
    "\n",
    "# Create a DataLoader for each dataset\n",
    "batch_size = 64\n",
    "\n",
    "train_data = TensorDataset(x_train_normalized_tensor, y_train_tensor)\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "val_data = TensorDataset(x_val_normalized_tensor, y_val_tensor)\n",
    "val_loader = DataLoader(val_data, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "test_data = TensorDataset(X_test_normalized_tensor, y_test_tensor)\n",
    "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Get the first batch of training data and shape\n",
    "for i, (X_batch, y_batch) in enumerate(train_loader):\n",
    "    print(\"X_batch shape:\", X_batch.shape)\n",
    "    print(\"y_batch shape:\", y_batch.shape)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "645ee309",
   "metadata": {},
   "source": [
    "### 3.2 Modeling\n",
    "\n",
    "#### 3.2.1 Define the 1D CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "afb591fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN1D(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN1D, self).__init__()\n",
    "\n",
    "        # convolutional layers -> relu -> convolutional layers -> relu -> \n",
    "        # pooling -> flatten -> fully connected layers\n",
    "        self.conv1 = nn.Conv1d(in_channels=12, out_channels=32, kernel_size=15, padding=12)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.conv2 = nn.Conv1d(in_channels=32, out_channels=64, kernel_size=9, padding=7)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.conv3 = nn.Conv1d(in_channels=64, out_channels=128, kernel_size=3, padding=4)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        # self.conv4 = nn.Conv1d(in_channels=128, out_channels=256, kernel_size=3, padding=2)\n",
    "        # self.relu4 = nn.ReLU()\n",
    "\n",
    "        self.pool = nn.MaxPool1d(3)\n",
    "        self.flat = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(22272, 512)\n",
    "        # self.fc1 = nn.Linear(44544, 512)\n",
    "        self.relu4 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(512, 75)  # Output the activation times\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.relu3(x)\n",
    "        # x = self.conv4(x)\n",
    "        # x = self.relu4(x)\n",
    "\n",
    "        x = self.pool(x)\n",
    "        x = self.flat(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu4(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fa6ddb4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class CNN1D(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(CNN1D, self).__init__()\n",
    "#         self.conv1 = nn.Conv1d(in_channels=12, out_channels=32, kernel_size=5, stride=1, padding=2)\n",
    "#         self.conv2 = nn.Conv1d(in_channels=32, out_channels=64, kernel_size=5, stride=1, padding=2)\n",
    "#         self.pool = nn.MaxPool1d(kernel_size=2, stride=2)\n",
    "#         self.fc1 = nn.Linear(64 * 125, 128)  # Adjust this size based on the output of the conv layers\n",
    "#         self.fc2 = nn.Linear(128, 75)  # Output size matches the target size (75)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = self.pool(F.relu(self.conv1(x)))\n",
    "#         x = self.pool(F.relu(self.conv2(x)))\n",
    "#         x = x.view(-1, 64 * 125)  # Adjust this size based on the output of the conv layers\n",
    "#         x = F.relu(self.fc1(x))\n",
    "#         x = self.fc2(x)\n",
    "#         return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69359550",
   "metadata": {},
   "source": [
    "#### 3.2.2 Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5265ae0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 3799.429931640625, Val Loss: 3790.7802734375\n",
      "Epoch 2, Loss: 3770.87890625, Val Loss: 3740.17041015625\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m     11\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 12\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train_normalized_tensor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(output, y_train_tensor)\n\u001b[1;32m     14\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[16], line 33\u001b[0m, in \u001b[0;36mCNN1D.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     29\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu3(x)\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# x = self.conv4(x)\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# x = self.relu4(x)\u001b[39;00m\n\u001b[0;32m---> 33\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpool\u001b[49m(x)\n\u001b[1;32m     34\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mflat(x)\n\u001b[1;32m     35\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc1(x)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1696\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1687\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;241m=\u001b[39m OrderedDict()\n\u001b[1;32m   1689\u001b[0m \u001b[38;5;66;03m# On the return type:\u001b[39;00m\n\u001b[1;32m   1690\u001b[0m \u001b[38;5;66;03m# We choose to return `Any` in the `__getattr__` type signature instead of a more strict `Union[Tensor, Module]`.\u001b[39;00m\n\u001b[1;32m   1691\u001b[0m \u001b[38;5;66;03m# This is done for better interop with various type checkers for the end users.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1694\u001b[0m \u001b[38;5;66;03m# See full discussion on the problems with returning `Union` here\u001b[39;00m\n\u001b[1;32m   1695\u001b[0m \u001b[38;5;66;03m# https://github.com/microsoft/pyright/issues/4213\u001b[39;00m\n\u001b[0;32m-> 1696\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getattr__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m   1697\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_parameters\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m:\n\u001b[1;32m   1698\u001b[0m         _parameters \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_parameters\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = CNN1D()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Configure Loss Function\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "num_epochs = 50  # or however many you deem necessary\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    output = model(x_train_normalized_tensor)\n",
    "    loss = criterion(output, y_train_tensor)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    # Evaluate on validation set\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        val_output = model(x_val_normalized_tensor)\n",
    "        val_loss = criterion(val_output, y_val_tensor)\n",
    "    \n",
    "    print(f'Epoch {epoch+1}, Loss: {loss.item()}, Val Loss: {val_loss.item()}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "083c629e",
   "metadata": {},
   "source": [
    "### 3.3 Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2563963",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Evaluate model\n",
    "# model.eval()\n",
    "\n",
    "# # Prepare test data\n",
    "# X_test_tensor = torch.tensor(X_test.reshape(4836, 12, 500), dtype=torch.float32)  # Add channel dimension\n",
    "# y_test_tensor = torch.tensor(y_test, dtype=torch.float32)\n",
    "\n",
    "# # Predict\n",
    "# with torch.no_grad():\n",
    "#     y_pred = model(X_test_tensor)\n",
    "\n",
    "# # Calculate loss\n",
    "# test_loss = criterion(y_pred, y_test_tensor)\n",
    "# print(f'Test Loss: {test_loss.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8badd5a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "# torch.save(model.state_dict(), '1dcnn.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "nbdime-conflicts": {
   "local_diff": [
    {
     "key": "kernelspec",
     "op": "add",
     "value": {
      "display_name": "PyTorch_Kernel",
      "language": "python",
      "name": "python3"
     }
    }
   ],
   "remote_diff": [
    {
     "key": "kernelspec",
     "op": "add",
     "value": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
     }
    }
   ]
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
