{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7f46fd54",
   "metadata": {},
   "source": [
    "# Task 3 Activation Map Reconstruction\n",
    "\n",
    "\n",
    "## PLAN\n",
    "\n",
    "### 1.1 Dataset Instruction\n",
    "\n",
    "Download the dataset from the [Dataset of Simulated Intracardiac Transmembrane Voltage Recordings and ECG Signals](https://library.ucsd.edu/dc/object/bb29449106) by running following command: \n",
    "\n",
    "```bash\n",
    "source download_intracardiac_dataset.sh\n",
    "```\n",
    "\n",
    "### 1.2 Task Description\n",
    "\n",
    "*Understand the time when each part of the heart is activated.*\n",
    "\n",
    "The objective is to build a model that can predict the activation times at the 75 myocardial points based on the ECG data from the 12 leads."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "76de3016",
   "metadata": {},
   "source": [
    "### 1.3 Load Modules and Preprocessing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "id": "bf9c735c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analysis\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import glob, re, os\n",
    "from typing import List\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Modeling\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# # Evaluate\n",
    "# from sklearn.metrics import mean_absolute_error\n",
    "# from sklearn.metrics import mean_squared_error\n",
    "# from sklearn.metrics import r2_score\n",
    "\n",
    "# Data processing\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "# Save model\n",
    "import pickle\n",
    "\n",
    "# Ignore warning\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "pd.set_option(\"display.max_rows\", 100)\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "id": "75d37977",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the cardiac_ml_tools.py script\n",
    "%run ./cardiac_challenge/notebooks/cardiac_ml_tools.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "id": "8c4eb774",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of file pairs: 16117\n",
      "Example of file pair:\n",
      "./cardiac_challenge/intracardiac_dataset/data_hearts_dd_0p2_geo_inn_act_3_bcl/pECGData_hearts_dd_0p2_geo_inn_act_3_bcl_bcl.1000.innerindex.0.volunteer.v13.npy\n",
      "./cardiac_challenge/intracardiac_dataset/data_hearts_dd_0p2_geo_inn_act_3_bcl/VmData_hearts_dd_0p2_geo_inn_act_3_bcl_bcl.1000.innerindex.0.volunteer.v13.npy\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "data_dirs = []\n",
    "regex = r'data_hearts_dd_0p2*'\n",
    "DIR = './cardiac_challenge/intracardiac_dataset/' # path to the intracardiac_dataset\n",
    "\n",
    "for x in os.listdir(DIR):\n",
    "    if re.match(regex, x):\n",
    "        data_dirs.append(DIR + x)\n",
    "file_pairs = read_data_dirs(data_dirs)\n",
    "print('Number of file pairs: {}'.format(len(file_pairs)))\n",
    "# example of file pair\n",
    "print(\"Example of file pair:\")\n",
    "print(\"{}\\n{}\".format(file_pairs[0][0], file_pairs[0][1]))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "19bb1412",
   "metadata": {},
   "source": [
    "### 1.4 Dataset details\n",
    "\n",
    "\n",
    "The dataset [Dataset of Simulated Intracardiac Transmembrane Voltage Recordings and ECG Signals](https://library.ucsd.edu/dc/object/bb29449106) \n",
    "consists of pairs of computationally simulated intracardiac transmembrane voltage recordings and ECG signals.\n",
    "In total, 16140 organ-level simulations were conducted to create this dataset.\n",
    "Simulations were performed using Lassen supercomputer at Lawrence Livermore National Lab (LLNL), concurrently utilizing 4 GPUs and 40 CPU cores.\n",
    "Each simulation produced pairs of 500ms-by-10 raw electrode signals and 500ms-by-75 transmembrane voltage signals.\n",
    "For convenience, we collect those signals in matrices and give them the following names:\n",
    "\n",
    "Tensor | Description | Shape | Notes\n",
    "--- | --- | --- | ---\n",
    "$X$ | Row electrode signals | $10 \\times 500$ | 10-lead ECG signals from the simulated torso (in [Dataset of Simulated Intracardiac Transmembrane Voltage Recordings and ECG Signals](https://library.ucsd.edu/dc/object/bb29449106))\n",
    "$V$ | Activation map | $75 \\times 500$ | Transmembrane voltage signals from the simulated heart (in [Dataset of Simulated Intracardiac Transmembrane Voltage Recordings and ECG Signals](https://library.ucsd.edu/dc/object/bb29449106))\n",
    "$E$ | 12-lead ECG signals | $12 \\times 500$ | 12-lead ECG signals obtained by `get_standard_leads`($X$)\n",
    "$A$ | Activation map | $75 \\times 1$ | Activation time, defined as $A_i = \\text{min}_j(V_{ij})$\n",
    "\n",
    "**IMPORTANT** : The raw data in the dataset consists of 10-lead ECG signals and 75-lead transmembrane voltage signals. The 12-lead ECG signals are obtained from the 10-lead ECG signals using the function `get_standard_leads` (in the file `cardiac_ml_tools.py`).\n",
    "\n",
    "The overall generation process is shown in the following image. The ECG signal is recorded using 10 virtual electrodes and the transmembrane voltages are recorded at 75 points within the myocardium. The transmembrane voltages are then used to generate the spatio-temporal activation maps."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b7ac66a2",
   "metadata": {},
   "source": [
    "![if picture not show, see path \"/cardiac_challenge/figures/data_generation.png\"](./cardiac_challenge/figures/data_generation.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "66018f88",
   "metadata": {},
   "source": [
    "## ANALYZE\n",
    "\n",
    "### 2.1 Getting the standard 12-lead ECG from the 10-lead ECG\n",
    "\n",
    "The function `get_standard_leads` (in the file `cardiac_ml_tools.py`) is used to obtain the 12-lead ECG signals from the 10-lead ECG signals. It implements the following transformation, where the (Wilson Lead) is defined as $Vw = 1/3*(RA + LA + LL)$:\n",
    "$$\n",
    "\\left\\{\n",
    "\\begin{array}{lll}\n",
    "    X_{:,1}  & \\to  & RA \\\\\n",
    "    X_{:,2}  & \\to  & LA \\\\\n",
    "    X_{:,3}  & \\to  & LL \\\\\n",
    "    X_{:,4}  & \\to  & RL \\\\\n",
    "    X_{:,5}  & \\to  & V1 \\\\\n",
    "    X_{:,6}  & \\to  & V2 \\\\\n",
    "    X_{:,7}  & \\to  & V3 \\\\\n",
    "    X_{:,8}  & \\to  & V4 \\\\\n",
    "    X_{:,9}  & \\to  & V5 \\\\\n",
    "    X_{:,10} & \\to &  V6 \\\\\n",
    "\\end{array}\n",
    "\\right.\n",
    "\\text{        and        }\n",
    "\\left\\{\n",
    "\\begin{array}{lll}          \n",
    "\\text{Lead } I& : & LA - RA \\\\\n",
    "\\text{Lead } II& : & LL - RA \\\\\n",
    "\\text{Lead } III& : & LL - LA \\\\\n",
    "\\text{Lead } aVR& : &  \\frac{3}{2} (RA - Vw) \\\\\n",
    "\\text{Lead } aVL& : &  \\frac{3}{2} (LA - Vw) \\\\\n",
    "\\text{Lead } aVF& : &  \\frac{3}{2} (LL - Vw)\\\\ \n",
    "\\text{Lead } V1 & : & V1 - Vw \\\\\n",
    "\\text{Lead } V2 & : & V2 - Vw \\\\\n",
    "\\text{Lead } V3 & : & V3 - Vw \\\\\n",
    "\\text{Lead } V4 & : & V4 - Vw \\\\\n",
    "\\text{Lead } V5 & : & V5 - Vw \\\\\n",
    "\\text{Lead } V6 & : & V6 - Vw \\\\\n",
    "\\end{array}\n",
    "\\right.\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "id": "cc3bed18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Example of file pair\n",
    "# case = 213\n",
    "# # ECG plot\n",
    "# row = 3 \n",
    "# column = 4\n",
    "# num_timesteps = 500\n",
    "# plt.figure(figsize=(10, 7))\n",
    "# titles = [\"I\", \"II\", \"III\", \"aVR\", \"aVL\", \"aVF\", \"V1\", \"V2\", \"V3\", \"V4\", \"V5\", \"V6\"]\n",
    "# reorder = {1:1,2:5,3:9,4:2,5:6,6:10,7:3,8:7,9:11,10:4,11:8,12:12} # reorder the leads to standard 12-lead ECG display\n",
    "\n",
    "# print('Case {} : {}'.format(case, file_pairs[case][0]))\n",
    "# pECGData = np.load(file_pairs[case][0])\n",
    "# pECGData = get_standard_leads(pECGData)\n",
    "\n",
    "# # create a figure with 12 subplots\n",
    "# for i in range(pECGData.shape[1]):\n",
    "#     plt.subplot(row, column, reorder[i + 1])\n",
    "#     plt.plot(pECGData[0:num_timesteps,i],'r', color='blue', alpha=0.8)\n",
    "#     plt.title(titles[i])\n",
    "#     # plt.plot(visible=True, color='blue', linestyle='-')\n",
    "#     plt.minorticks_on()\n",
    "#     # plt.plot(visible=True, color='blue', linestyle='-', alpha=0.2)\n",
    "#     plt.xlabel('msec')\n",
    "#     plt.ylabel('mV')\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n",
    "# # close\n",
    "# plt.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7346c1bb",
   "metadata": {},
   "source": [
    "### 2.2 Getting the activation map from the transmembrane voltages\n",
    "\n",
    "The funtion `get_activation_map` (in the file `cardiac_ml_tools.py`) is used to obtain the activation map from the transmembrane voltages. It implements the following transformation $A_i = \\text{min}_j(V_{ij})$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "id": "ee45c6de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Example of file pair\n",
    "# case = 213\n",
    "# # plt.figure(figsize=(1, 10))\n",
    "# plt.figure(figsize=(15, 2))\n",
    "\n",
    "# print('Case {} : {}'.format(case, file_pairs[case][0]))\n",
    "# VmData = np.load(file_pairs[case][1])\n",
    "\n",
    "# ActTime = get_activation_time(VmData)\n",
    "\n",
    "# # plot the Activation Time array\n",
    "# plt.imshow(ActTime.T, cmap='jet', interpolation='nearest', aspect='auto')\n",
    "# plt.title('Activation Time')\n",
    "# plt.colorbar()\n",
    "# plt.grid(visible=True, which='major', color='#666666', linestyle='-')\n",
    "# plt.minorticks_on()\n",
    "# # not yticks\n",
    "# plt.yticks([])\n",
    "# plt.grid(visible=True, which='minor', color='#999999', linestyle='-', alpha=0.2)\n",
    "# plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c0123209",
   "metadata": {},
   "source": [
    "### 3.3 Learning the mapping from the 12-lead ECG to the activation map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "id": "c1b6d72c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # make a plot with the \"pECGData\" -> \"ActTime\"\n",
    "# case = 213\n",
    "\n",
    "# print('Case {} : {}'.format(case, file_pairs[case][0]))\n",
    "# pECGData = np.load(file_pairs[case][0])\n",
    "# pECGData = get_standard_leads(pECGData)\n",
    "\n",
    "# print('Case {} : {}'.format(case, file_pairs[case][0]))\n",
    "# VmData = np.load(file_pairs[case][1])\n",
    "# ActTime = get_activation_time(VmData)\n",
    "\n",
    "# # plot in row the tensors pECGData and ActTime with an arrow pointing to the activation time\n",
    "# row = 1\n",
    "# column = 3\n",
    "# plt.figure(figsize=(20, 5))\n",
    "# plt.subplot(row, column, 1)\n",
    "# # plot pECGData transposed\n",
    "# plt.imshow(pECGData.T, cmap='jet', interpolation='nearest', aspect='auto')\n",
    "# plt.title('pECGData')\n",
    "# plt.subplot(row, column, 2)\n",
    "# # print an arrow\n",
    "# plt.text(0.5, 0.5, '-------->', horizontalalignment='center', verticalalignment='center', fontsize=20)\n",
    "# plt.axis('off')\n",
    "# plt.subplot(row, column, 3)\n",
    "# # plot ActTime\n",
    "# plt.imshow(ActTime, cmap='jet', interpolation='nearest', aspect='auto')\n",
    "# # not xticks\n",
    "# plt.xticks([])\n",
    "# plt.title('ActTime')\n",
    "# plt.show()\n",
    "# plt.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "204d7bd1",
   "metadata": {},
   "source": [
    "**Tricks**\n",
    "\n",
    "As in many machine learning problems, normalization of the data might be helpful or even necessary. Different normalization schemes might be applied."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ffeee68",
   "metadata": {},
   "source": [
    "## CONSTRUCT\n",
    "\n",
    "**Model: 1D CNN**\n",
    "\n",
    "**Approach**\n",
    "\n",
    "We to flatten each 2D sample (12x500) from the ECG data into a 1D row, transforming each sample from a matrix into a long vector. Then, you want to stack all these vectors from over 16,000 samples into a single large dataset where each row represents one sample, fully flattened, resulting in a dataset with dimensions of (16000, 6000) — since 12 x 500 = 6000.\n",
    "\n",
    "Here’s the step-by-step plan to achieve this:\n",
    "\n",
    "1. **Flatten Each Sample**: Each 12x500 matrix will be reshaped into a single row of 6000 elements. This converts the 2D feature set of each sample into a 1D array.\n",
    "\n",
    "2. **Stack All Samples**: After flattening each sample, you'll stack them vertically to create a new dataset where each row corresponds to one of the original 2D samples, now represented as a long 1D vector.\n",
    "\n",
    "3. **Create a Uniform Dataset**: The result will be a large dataset where every sample is consistently formatted in a single row, making it easier to handle in terms of data processing and input into machine learning models.\n",
    "\n",
    "4. **Store or Process This Dataset**: Depending on the final application, this dataset can then be either stored for further use, processed for normalization, or directly used as input for machine learning models, particularly for tasks like clustering, classification, or regression.\n",
    "\n",
    "This approach effectively transforms a complex 2D dataset into a more manageable 1D format, albeit at the expense of increasing the dimensionality of each data point. This can be useful for certain types of analyses or machine learning models that require a flat vector per sample.\n",
    "\n",
    "**Combine Dataset Approach**\n",
    "\n",
    "Given that your full dataset contains over 16,000 samples, here's a graduated approach to determining an initial subset size:\n",
    "\n",
    "- **Initial Proof of Concept**: Start with a very small amount of data, perhaps around **100 to 500 samples**. This size is usually sufficient to ensure that your data loading, processing, and model training pipelines are functioning correctly without excessive computational overhead.\n",
    "\n",
    "- **Preliminary Testing**: Once your initial setup is verified to be working correctly, increase the size to about **1,000 to 2,000 samples**. This provides a more statistically significant dataset to start tuning hyperparameters and testing model performance while still being manageable in terms of computational resources and time.\n",
    "\n",
    "- **Detailed Testing and Validation**: If the model performs well on 1,000 to 2,000 samples, consider using a larger subset, such as **5,000 to 10,000 samples**, to further refine your model and prepare for full-scale training. This step is crucial for understanding how well the model scales with data size and for final adjustments before deploying the model on the entire dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca82414b",
   "metadata": {},
   "source": [
    "\n",
    "### 3.1 Data Processing\n",
    "\n",
    "#### 3.1.1 Combine Dataset\n",
    "\n",
    "In PyTorch, when dealing with 1D convolutional neural networks (CNNs), the data should be reshaped to follow the format `[batch_size, channels, length]`, where:\n",
    "\n",
    "- **batch_size** is the number of samples in a batch.\n",
    "- **channels** corresponds to the number of features per timestep, often equated with the number of sensors or measurement types in your dataset.\n",
    "- **length** is the number of timesteps per sample.\n",
    "\n",
    "In this case, we do `[num_samples, 12, 500]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "id": "8e32d1dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If file active.npy and ecg.npy are already created, load them\n",
    "if os.path.exists('./combine_dataset/ecg_data.npy') and os.path.exists('./combine_dataset/active_time.npy'):\n",
    "# if os.path.exists('./combine_dataset/ecg_data_5000.npy') and os.path.exists('./combine_dataset/active_time_5000.npy'):\n",
    "    ECGData = np.load('./combine_dataset/ecg_data.npy')\n",
    "    ActTime = np.load('./combine_dataset/active_time.npy')\n",
    "    # ECGData = np.load('./combine_dataset/ecg_data_5000.npy')\n",
    "    # ActTime = np.load('./combine_dataset/active_time_5000.npy')\n",
    "\n",
    "else:\n",
    "    # file_pairs is a list where each element is a tuple containing the file paths for ECG data and activation time data\n",
    "    num_samples = 16117  # Number of samples to process\n",
    "    # num_samples = 5000  # Number of samples to process\n",
    "    num_timesteps = 500  # Each ECG data has 500 timesteps\n",
    "    num_leads = 12  # Standard ECG leads count after processing\n",
    "\n",
    "    # Initialize arrays to store combined data\n",
    "    ECGData = np.zeros((num_samples, num_leads, num_timesteps))  # 3D array for ECG data\n",
    "    ActTime = np.zeros((num_samples, 75))  # Store 75 activation times per sample\n",
    "\n",
    "    # Process each sample\n",
    "    for i in range(num_samples):\n",
    "        # Load ECG data\n",
    "        pECGData = np.load(file_pairs[i][0])\n",
    "        pECGData = get_standard_leads(pECGData)  # Convert to 12 standard leads\n",
    "        ECGData[i, :, :] = pECGData.T  # Store in 3D array directly\n",
    "\n",
    "        # Load and process activation time data\n",
    "        VmData = np.load(file_pairs[i][1])\n",
    "        ActTime[i, :] = get_activation_time(VmData).flatten()  # Flatten the (75, 1) array to fit into (75,) array\n",
    "\n",
    "    # Create directory if it does not exist\n",
    "    output_dir = './combine_dataset'\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # Save combined datasets to .npy format\n",
    "    np.save(os.path.join(output_dir, 'ecg_data.npy'), ECGData)\n",
    "    np.save(os.path.join(output_dir, 'active_time.npy'), ActTime)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa015579",
   "metadata": {},
   "source": [
    "After combine, check them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "id": "0af15993",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ECGData shape: (16117, 12, 500)\n",
      "ActTime shape: (16117, 75)\n"
     ]
    }
   ],
   "source": [
    "print(\"ECGData shape: {}\".format(ECGData.shape))\n",
    "print(\"ActTime shape: {}\".format(ActTime.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38ad071c",
   "metadata": {},
   "source": [
    "\n",
    "#### 3.1.2 Split Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "id": "f4365507",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((12893, 12, 500),\n",
       " (12893, 75),\n",
       " (1612, 12, 500),\n",
       " (1612, 75),\n",
       " (1612, 12, 500),\n",
       " (1612, 75))"
      ]
     },
     "execution_count": 415,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shuffle indices\n",
    "indices = np.arange(ECGData.shape[0])\n",
    "shuffled_indices = shuffle(indices, random_state=42)\n",
    "\n",
    "# Define the split ratios\n",
    "train_ratio = 0.8  # 80% training\n",
    "val_ratio = 0.1  # 10% validation\n",
    "test_ratio = 0.1  # 10% test\n",
    "\n",
    "# Calculate the split points\n",
    "train_split = int(len(shuffled_indices) * train_ratio)\n",
    "val_split = int(len(shuffled_indices) * (train_ratio + val_ratio))\n",
    "\n",
    "# Split indices into training, validation, and test sets\n",
    "train_indices = shuffled_indices[:train_split]\n",
    "val_indices = shuffled_indices[train_split:val_split]\n",
    "test_indices = shuffled_indices[val_split:]\n",
    "\n",
    "# Use indices to create training, validation, and test data\n",
    "x_train = ECGData[train_indices]\n",
    "y_train = ActTime[train_indices]\n",
    "x_val = ECGData[val_indices]\n",
    "y_val = ActTime[val_indices]\n",
    "x_test = ECGData[test_indices]\n",
    "y_test = ActTime[test_indices]\n",
    "\n",
    "# Print the shapes of the data\n",
    "x_train.shape, y_train.shape, x_val.shape, y_val.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b105e24",
   "metadata": {},
   "source": [
    "#### 3.1.3 Normalize Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "id": "30a2b38a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min values: [tensor(-5.9469), tensor(-5.5515), tensor(-3.5719), tensor(-4.2882), tensor(-4.2226), tensor(-3.1564), tensor(-2.4479), tensor(-2.3431), tensor(-2.5146), tensor(-2.3105), tensor(-1.9630), tensor(-2.3298)] \n",
      "Max values: [tensor(4.5094), tensor(4.2176), tensor(4.2389), tensor(5.4646), tensor(3.5553), tensor(3.0083), tensor(2.9844), tensor(2.3593), tensor(2.2054), tensor(2.0142), tensor(1.6994), tensor(2.1287)]\n",
      "Min values: [tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.)] \n",
      "Max values: [tensor(158.), tensor(162.), tensor(153.), tensor(147.), tensor(164.), tensor(165.), tensor(162.), tensor(163.), tensor(162.), tensor(149.), tensor(148.), tensor(147.), tensor(145.), tensor(152.), tensor(153.), tensor(150.), tensor(135.), tensor(139.), tensor(152.), tensor(156.), tensor(150.), tensor(158.), tensor(163.), tensor(164.), tensor(171.), tensor(176.), tensor(178.), tensor(162.), tensor(155.), tensor(173.), tensor(172.), tensor(167.), tensor(143.), tensor(152.), tensor(160.), tensor(170.), tensor(168.), tensor(156.), tensor(167.), tensor(157.), tensor(162.), tensor(163.), tensor(156.), tensor(170.), tensor(170.), tensor(163.), tensor(177.), tensor(168.), tensor(181.), tensor(170.), tensor(175.), tensor(169.), tensor(171.), tensor(167.), tensor(182.), tensor(185.), tensor(179.), tensor(172.), tensor(162.), tensor(169.), tensor(163.), tensor(150.), tensor(150.), tensor(150.), tensor(169.), tensor(170.), tensor(167.), tensor(164.), tensor(145.), tensor(163.), tensor(160.), tensor(155.), tensor(176.), tensor(171.), tensor(165.)]\n"
     ]
    }
   ],
   "source": [
    "# Convert numpy arrays to PyTorch tensors\n",
    "x_train_tensor = torch.tensor(x_train, dtype=torch.float32)\n",
    "x_val_tensor = torch.tensor(x_val, dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(x_test, dtype=torch.float32)\n",
    "\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32)\n",
    "y_val_tensor = torch.tensor(y_val, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.float32)\n",
    "\n",
    "# Calculate the min and max values and add to list\n",
    "x_min_list = []\n",
    "x_max_list = []\n",
    "y_min_list = []\n",
    "y_max_list = []\n",
    "\n",
    "for i in range(x_train_tensor.shape[1]): # loop 12 leads\n",
    "    min_value = x_train_tensor[:, i].min()\n",
    "    max_value = x_train_tensor[:, i].max()\n",
    "    x_min_list.append(min_value)\n",
    "    x_max_list.append(max_value)\n",
    "\n",
    "for i in range(y_train_tensor.shape[1]): # loop 75 activation times\n",
    "    min_value = y_train_tensor[:, i].min()\n",
    "    max_value = y_train_tensor[:, i].max()\n",
    "    y_min_list.append(min_value)\n",
    "    y_max_list.append(max_value)\n",
    "\n",
    "print(\"Min values:\", x_min_list, \"\\nMax values:\", x_max_list)\n",
    "print(\"Min values:\", y_min_list, \"\\nMax values:\", y_max_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "id": "f58fd456",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized training data shape: (12893, 12, 500)\n",
      "Normalized validation data shape: (1612, 12, 500)\n",
      "Normalized test data shape: (1612, 12, 500)\n",
      "Normalized training labels shape: torch.Size([12893, 75])\n",
      "Normalized validation labels shape: torch.Size([1612, 75])\n",
      "Normalized test labels shape: torch.Size([1612, 75])\n"
     ]
    }
   ],
   "source": [
    "# Normalize the data\n",
    "def normalize_x(data, min_val, max_val):\n",
    "    # normalize_dataset = np.zeros(data.shape)\n",
    "    for i in range(data.shape[1]):\n",
    "        data[:, i] = np.divide(data[:, i], max_val[i])\n",
    "    return data\n",
    "\n",
    "# Normalize the datasets\n",
    "x_train_normalized = normalize_x(x_train, np.min(x_train), x_max_list)\n",
    "x_val_normalized = normalize_x(x_val, np.min(x_train), x_max_list)\n",
    "X_test_normalized = normalize_x(x_test, np.min(x_train), x_max_list)\n",
    "\n",
    "y_train_normalized = np.divide((y_train - y_train.min()), (y_train.max() - min_value))\n",
    "y_val_normalized = np.divide((y_val - y_train.min()), (y_train.max( )- min_value))\n",
    "y_test_normalized = np.divide((y_test - y_train.min()), (y_train.max() - min_value))\n",
    "\n",
    "# You can print the shapes to verify the sizes are correct and the operations have been applied uniformly\n",
    "print(\"Normalized training data shape:\", x_train_normalized.shape)\n",
    "print(\"Normalized validation data shape:\", x_val_normalized.shape)\n",
    "print(\"Normalized test data shape:\", X_test_normalized.shape)\n",
    "print(\"Normalized training labels shape:\", y_train_normalized.shape)\n",
    "print(\"Normalized validation labels shape:\", y_val_normalized.shape)\n",
    "print(\"Normalized test labels shape:\", y_test_normalized.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "id": "6b21c601",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # plot the 1 sample from x_train_normalized, 12 leads total\n",
    "# plt.figure(figsize=(10, 7))\n",
    "# titles = [\"I\", \"II\", \"III\", \"aVR\", \"aVL\", \"aVF\", \"V1\", \"V2\", \"V3\", \"V4\", \"V5\", \"V6\"]\n",
    "\n",
    "# for i in range(x_train.shape[1]):\n",
    "#     plt.subplot(3, 4, i + 1)\n",
    "#     plt.plot(x_train[10, i, :], color='blue', alpha=0.8)\n",
    "#     plt.title(titles[i])\n",
    "#     plt.minorticks_on()\n",
    "#     plt.xlabel('msec')\n",
    "#     plt.ylabel('mV')\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n",
    "# plt.close()\n",
    "\n",
    "\n",
    "# plt.figure(figsize=(10, 7))\n",
    "# # create a figure with 12 subplots\n",
    "# for i in range(x_train_normalized.shape[1]):\n",
    "#     plt.subplot(3, 4, i + 1)\n",
    "#     plt.plot(x_train_normalized[10, i, :], color='blue', alpha=0.8)\n",
    "#     plt.title(titles[i])\n",
    "#     plt.minorticks_on()\n",
    "#     plt.xlabel('msec')\n",
    "#     plt.ylabel('mV')\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n",
    "# plt.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "id": "1994339c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_batch shape: torch.Size([64, 12, 500])\n",
      "y_batch shape: torch.Size([64, 75])\n"
     ]
    }
   ],
   "source": [
    "# convery normalized to tensor\n",
    "x_train_normalized_tensor = torch.tensor(x_train_normalized, dtype=torch.float32)\n",
    "x_val_normalized_tensor = torch.tensor(x_val_normalized, dtype=torch.float32)\n",
    "X_test_normalized_tensor = torch.tensor(X_test_normalized, dtype=torch.float32)\n",
    "\n",
    "y_train_normalized_tensor = torch.tensor(y_train_normalized, dtype=torch.float32)\n",
    "y_val_normalized_tensor = torch.tensor(y_val_normalized, dtype=torch.float32)\n",
    "y_test_normalized_tensor = torch.tensor(y_test_normalized, dtype=torch.float32)\n",
    "\n",
    "# Create a DataLoader for each dataset\n",
    "batch_size = 64\n",
    "\n",
    "train_data = TensorDataset(x_train_normalized_tensor, y_train_normalized_tensor)\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "val_data = TensorDataset(x_val_normalized_tensor, y_val_normalized_tensor)\n",
    "val_loader = DataLoader(val_data, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "test_data = TensorDataset(X_test_normalized_tensor, y_test_normalized_tensor)\n",
    "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Get the first batch of training data and shape\n",
    "for i, (X_batch, y_batch) in enumerate(train_loader):\n",
    "    print(\"X_batch shape:\", X_batch.shape)\n",
    "    print(\"y_batch shape:\", y_batch.shape)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "645ee309",
   "metadata": {},
   "source": [
    "### 3.2 Modeling\n",
    "\n",
    "#### 3.2.1 Define the 1D CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "id": "afb591fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN1D(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN1D, self).__init__()\n",
    "\n",
    "        # convolutional layers -> relu -> convolutional layers -> relu -> \n",
    "        # pooling -> flatten -> fully connected layers\n",
    "        self.conv1 = nn.Conv1d(in_channels=12, out_channels=32, kernel_size=15, padding=12)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.conv2 = nn.Conv1d(in_channels=32, out_channels=64, kernel_size=9, padding=7)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.conv3 = nn.Conv1d(in_channels=64, out_channels=128, kernel_size=3, padding=4)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        # self.conv4 = nn.Conv1d(in_channels=128, out_channels=256, kernel_size=3, padding=2)\n",
    "        # self.relu4 = nn.ReLU()\n",
    "\n",
    "        self.pool = nn.MaxPool1d(3)\n",
    "        self.flat = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(22272, 512)\n",
    "        # self.fc1 = nn.Linear(44544, 512)\n",
    "        self.relu4 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(512, 75)  # Output the activation times\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.relu3(x)\n",
    "        # x = self.conv4(x)\n",
    "        # x = self.relu4(x)\n",
    "\n",
    "        x = self.pool(x)\n",
    "        x = self.flat(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu4(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "id": "fa6ddb4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class CNN1D(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(CNN1D, self).__init__()\n",
    "#         self.conv1 = nn.Conv1d(in_channels=12, out_channels=32, kernel_size=5, stride=1, padding=2)\n",
    "#         self.conv2 = nn.Conv1d(in_channels=32, out_channels=64, kernel_size=5, stride=1, padding=2)\n",
    "#         self.pool = nn.MaxPool1d(kernel_size=2, stride=2)\n",
    "#         self.fc1 = nn.Linear(64 * 125, 128)  # Adjust this size based on the output of the conv layers\n",
    "#         self.fc2 = nn.Linear(128, 75)  # Output size matches the target size (75)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = self.pool(F.relu(self.conv1(x)))\n",
    "#         x = self.pool(F.relu(self.conv2(x)))\n",
    "#         x = x.view(-1, 64 * 125)  # Adjust this size based on the output of the conv layers\n",
    "#         x = F.relu(self.fc1(x))\n",
    "#         x = self.fc2(x)\n",
    "#         return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69359550",
   "metadata": {},
   "source": [
    "#### 3.2.2 Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "id": "5265ae0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = CNN1D()\n",
    "# optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# # Configure Loss Function\n",
    "# criterion = nn.MSELoss()\n",
    "\n",
    "# num_epochs = 10  # or however many you deem necessary\n",
    "\n",
    "# for epoch in range(num_epochs):\n",
    "#     model.train()\n",
    "#     optimizer.zero_grad()\n",
    "#     output = model(x_train_normalized_tensor)\n",
    "#     loss = criterion(output, y_train_normalized_tensor)\n",
    "#     loss.backward()\n",
    "#     optimizer.step()\n",
    "    \n",
    "#     # Evaluate on validation set\n",
    "#     model.eval()\n",
    "#     with torch.no_grad():\n",
    "#         val_output = model(x_val_normalized_tensor)\n",
    "#         val_loss = criterion(val_output, y_val_normalized_tensor)\n",
    "    \n",
    "#     print(f'Epoch {epoch+1}, Loss: {loss.item()}, Val Loss: {val_loss.item()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "id": "b1af4856",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 2.157438649330288, Val Loss: 0.007369553204625845\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[423], line 22\u001b[0m\n\u001b[1;32m     20\u001b[0m     loss \u001b[38;5;241m=\u001b[39m criterion(output, y_batch)\n\u001b[1;32m     21\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m---> 22\u001b[0m     \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m     avg_train_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;66;03m# train_losses.append()\u001b[39;00m\n\u001b[1;32m     25\u001b[0m \n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# Evaluate on validation set\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/optim/optimizer.py:391\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    386\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    387\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    388\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    389\u001b[0m             )\n\u001b[0;32m--> 391\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    392\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    394\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/optim/optimizer.py:76\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     74\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     75\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n\u001b[0;32m---> 76\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     78\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/optim/adam.py:168\u001b[0m, in \u001b[0;36mAdam.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    157\u001b[0m     beta1, beta2 \u001b[38;5;241m=\u001b[39m group[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbetas\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m    159\u001b[0m     has_complex \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_group(\n\u001b[1;32m    160\u001b[0m         group,\n\u001b[1;32m    161\u001b[0m         params_with_grad,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    165\u001b[0m         max_exp_avg_sqs,\n\u001b[1;32m    166\u001b[0m         state_steps)\n\u001b[0;32m--> 168\u001b[0m     \u001b[43madam\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    169\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    170\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    171\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    172\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    173\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    174\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m        \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mamsgrad\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    176\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    178\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    179\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mweight_decay\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    181\u001b[0m \u001b[43m        \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43meps\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmaximize\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    183\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforeach\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mforeach\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    184\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcapturable\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    185\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdifferentiable\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    186\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfused\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfused\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    187\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgrad_scale\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    188\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfound_inf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    189\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    191\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/optim/adam.py:318\u001b[0m, in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    315\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    316\u001b[0m     func \u001b[38;5;241m=\u001b[39m _single_tensor_adam\n\u001b[0;32m--> 318\u001b[0m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    319\u001b[0m \u001b[43m     \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    320\u001b[0m \u001b[43m     \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    321\u001b[0m \u001b[43m     \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    322\u001b[0m \u001b[43m     \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    323\u001b[0m \u001b[43m     \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    324\u001b[0m \u001b[43m     \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    325\u001b[0m \u001b[43m     \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    326\u001b[0m \u001b[43m     \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    327\u001b[0m \u001b[43m     \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    328\u001b[0m \u001b[43m     \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    329\u001b[0m \u001b[43m     \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    330\u001b[0m \u001b[43m     \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    331\u001b[0m \u001b[43m     \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    332\u001b[0m \u001b[43m     \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcapturable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    333\u001b[0m \u001b[43m     \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdifferentiable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    334\u001b[0m \u001b[43m     \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrad_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    335\u001b[0m \u001b[43m     \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfound_inf\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/optim/adam.py:441\u001b[0m, in \u001b[0;36m_single_tensor_adam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, has_complex, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[1;32m    439\u001b[0m         denom \u001b[38;5;241m=\u001b[39m (max_exp_avg_sqs[i]\u001b[38;5;241m.\u001b[39msqrt() \u001b[38;5;241m/\u001b[39m bias_correction2_sqrt)\u001b[38;5;241m.\u001b[39madd_(eps)\n\u001b[1;32m    440\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 441\u001b[0m         denom \u001b[38;5;241m=\u001b[39m (\u001b[43mexp_avg_sq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqrt\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m/\u001b[39m bias_correction2_sqrt)\u001b[38;5;241m.\u001b[39madd_(eps)\n\u001b[1;32m    443\u001b[0m     param\u001b[38;5;241m.\u001b[39maddcdiv_(exp_avg, denom, value\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39mstep_size)\n\u001b[1;32m    445\u001b[0m \u001b[38;5;66;03m# Lastly, switch back to complex view\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = CNN1D()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Configure Loss Function\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "num_epochs = 5  # or however many you deem necessary\n",
    "\n",
    "# Plot the training VS validation losses\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    avg_train_loss = 0\n",
    "\n",
    "    for i, (X_batch, y_batch) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        output = model(X_batch)\n",
    "        loss = criterion(output, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        avg_train_loss += loss.item()\n",
    "        # train_losses.append()\n",
    "    \n",
    "    # Evaluate on validation set\n",
    "    model.eval()    \n",
    "\n",
    "    with torch.no_grad():\n",
    "        val_output = model(x_val_normalized_tensor)\n",
    "        val_loss = criterion(val_output, y_val_normalized_tensor)\n",
    "        val_losses.append(val_loss.item())\n",
    "\n",
    "    train_losses.append(avg_train_loss / len(train_loader))\n",
    "    \n",
    "    print(f'Epoch {epoch+1}, Loss: {avg_train_loss}, Val Loss: {val_loss.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da1bf6ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1010\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 369,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(train_losses))\n",
    "len(val_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "641c287b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the training and validation losses\n",
    "# plt.figure(figsize=(10, 7))\n",
    "plt.plot(train_losses, label='Training Loss')\n",
    "plt.plot(val_losses, label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "083c629e",
   "metadata": {},
   "source": [
    "### 3.3 Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2563963",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Evaluate model\n",
    "# model.eval()\n",
    "\n",
    "# # Prepare test data\n",
    "# X_test_tensor = torch.tensor(X_test.reshape(4836, 12, 500), dtype=torch.float32)  # Add channel dimension\n",
    "# y_test_tensor = torch.tensor(y_test, dtype=torch.float32)\n",
    "\n",
    "# # Predict\n",
    "# with torch.no_grad():\n",
    "#     y_pred = model(X_test_tensor)\n",
    "\n",
    "# # Calculate loss\n",
    "# test_loss = criterion(y_pred, y_test_tensor)\n",
    "# print(f'Test Loss: {test_loss.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8badd5a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "# torch.save(model.state_dict(), '1dcnn.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "nbdime-conflicts": {
   "local_diff": [
    {
     "key": "kernelspec",
     "op": "add",
     "value": {
      "display_name": "PyTorch_Kernel",
      "language": "python",
      "name": "python3"
     }
    }
   ],
   "remote_diff": [
    {
     "key": "kernelspec",
     "op": "add",
     "value": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
     }
    }
   ]
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
