{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7f46fd54",
   "metadata": {},
   "source": [
    "# Task 3 Activation Map Reconstruction\n",
    "\n",
    "\n",
    "## PLAN\n",
    "\n",
    "### 1.1 Dataset Instruction\n",
    "\n",
    "Download the dataset from the [Dataset of Simulated Intracardiac Transmembrane Voltage Recordings and ECG Signals](https://library.ucsd.edu/dc/object/bb29449106) by running following command: \n",
    "\n",
    "```bash\n",
    "source download_intracardiac_dataset.sh\n",
    "```\n",
    "\n",
    "### 1.2 Task Description\n",
    "\n",
    "*Understand the time when each part of the heart is activated.*\n",
    "\n",
    "The objective is to build a model that can predict the activation times at the 75 myocardial points based on the ECG data from the 12 leads."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "76de3016",
   "metadata": {},
   "source": [
    "### 1.3 Load Modules and Preprocessing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf9c735c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analysis\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import glob, re, os\n",
    "from typing import List\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Modeling\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# # Evaluate\n",
    "# from sklearn.metrics import mean_absolute_error\n",
    "# from sklearn.metrics import mean_squared_error\n",
    "# from sklearn.metrics import r2_score\n",
    "\n",
    "# # Data processing\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# from sklearn.calibration import LabelEncoder\n",
    "\n",
    "# Save model\n",
    "import pickle\n",
    "\n",
    "# Ignore warning\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "pd.set_option(\"display.max_rows\", 100)\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aee11ba5",
   "metadata": {},
   "source": [
    "# Task 3 Activation Map Reconstruction Cont 1\n",
    "\n",
    "## CONSTRUCT\n",
    "\n",
    "**Goal**\n",
    "\n",
    "This file combine 500 sample. \n",
    "\n",
    "### Before Start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d104db5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob, re, os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import List\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Ignore warning\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "pd.set_option(\"display.max_rows\", 100)\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "75d37977",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the cardiac_ml_tools.py script\n",
    "%run ./cardiac_challenge/notebooks/cardiac_ml_tools.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8c4eb774",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of file pairs: 16117\n",
      "Example of file pair:\n",
      "./cardiac_challenge/intracardiac_dataset/data_hearts_dd_0p2_geo_act_3_bcl/pECGData_hearts_dd_0p2_geo_act_3_bcl_bcl.1000.pattern.0.volunteer.v1.npy\n",
      "./cardiac_challenge/intracardiac_dataset/data_hearts_dd_0p2_geo_act_3_bcl/VmData_hearts_dd_0p2_geo_act_3_bcl_bcl.1000.pattern.0.volunteer.v1.npy\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "data_dirs = []\n",
    "regex = r'data_hearts_dd_0p2*'\n",
    "DIR = './cardiac_challenge/intracardiac_dataset/' # path to the intracardiac_dataset\n",
    "\n",
    "for x in os.listdir(DIR):\n",
    "    if re.match(regex, x):\n",
    "        data_dirs.append(DIR + x)\n",
    "file_pairs = read_data_dirs(data_dirs)\n",
    "print('Number of file pairs: {}'.format(len(file_pairs)))\n",
    "# example of file pair\n",
    "print(\"Example of file pair:\")\n",
    "print(\"{}\\n{}\".format(file_pairs[0][0], file_pairs[0][1]))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "19bb1412",
   "metadata": {},
   "source": [
    "### 1.4 Dataset details\n",
    "\n",
    "\n",
    "The dataset [Dataset of Simulated Intracardiac Transmembrane Voltage Recordings and ECG Signals](https://library.ucsd.edu/dc/object/bb29449106) \n",
    "consists of pairs of computationally simulated intracardiac transmembrane voltage recordings and ECG signals.\n",
    "In total, 16140 organ-level simulations were conducted to create this dataset.\n",
    "Simulations were performed using Lassen supercomputer at Lawrence Livermore National Lab (LLNL), concurrently utilizing 4 GPUs and 40 CPU cores.\n",
    "Each simulation produced pairs of 500ms-by-10 raw electrode signals and 500ms-by-75 transmembrane voltage signals.\n",
    "For convenience, we collect those signals in matrices and give them the following names:\n",
    "\n",
    "Tensor | Description | Shape | Notes\n",
    "--- | --- | --- | ---\n",
    "$X$ | Row electrode signals | $10 \\times 500$ | 10-lead ECG signals from the simulated torso (in [Dataset of Simulated Intracardiac Transmembrane Voltage Recordings and ECG Signals](https://library.ucsd.edu/dc/object/bb29449106))\n",
    "$V$ | Activation map | $75 \\times 500$ | Transmembrane voltage signals from the simulated heart (in [Dataset of Simulated Intracardiac Transmembrane Voltage Recordings and ECG Signals](https://library.ucsd.edu/dc/object/bb29449106))\n",
    "$E$ | 12-lead ECG signals | $12 \\times 500$ | 12-lead ECG signals obtained by `get_standard_leads`($X$)\n",
    "$A$ | Activation map | $75 \\times 1$ | Activation time, defined as $A_i = \\text{min}_j(V_{ij})$\n",
    "\n",
    "**IMPORTANT** : The raw data in the dataset consists of 10-lead ECG signals and 75-lead transmembrane voltage signals. The 12-lead ECG signals are obtained from the 10-lead ECG signals using the function `get_standard_leads` (in the file `cardiac_ml_tools.py`).\n",
    "\n",
    "The overall generation process is shown in the following image. The ECG signal is recorded using 10 virtual electrodes and the transmembrane voltages are recorded at 75 points within the myocardium. The transmembrane voltages are then used to generate the spatio-temporal activation maps."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b7ac66a2",
   "metadata": {},
   "source": [
    "![if picture not show, see path \"/cardiac_challenge/figures/data_generation.png\"](./cardiac_challenge/figures/data_generation.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "66018f88",
   "metadata": {},
   "source": [
    "## ANALYZE\n",
    "\n",
    "### 2.1 Getting the standard 12-lead ECG from the 10-lead ECG\n",
    "\n",
    "The function `get_standard_leads` (in the file `cardiac_ml_tools.py`) is used to obtain the 12-lead ECG signals from the 10-lead ECG signals. It implements the following transformation, where the (Wilson Lead) is defined as $Vw = 1/3*(RA + LA + LL)$:\n",
    "$$\n",
    "\\left\\{\n",
    "\\begin{array}{lll}\n",
    "    X_{:,1}  & \\to  & RA \\\\\n",
    "    X_{:,2}  & \\to  & LA \\\\\n",
    "    X_{:,3}  & \\to  & LL \\\\\n",
    "    X_{:,4}  & \\to  & RL \\\\\n",
    "    X_{:,5}  & \\to  & V1 \\\\\n",
    "    X_{:,6}  & \\to  & V2 \\\\\n",
    "    X_{:,7}  & \\to  & V3 \\\\\n",
    "    X_{:,8}  & \\to  & V4 \\\\\n",
    "    X_{:,9}  & \\to  & V5 \\\\\n",
    "    X_{:,10} & \\to &  V6 \\\\\n",
    "\\end{array}\n",
    "\\right.\n",
    "\\text{        and        }\n",
    "\\left\\{\n",
    "\\begin{array}{lll}          \n",
    "\\text{Lead } I& : & LA - RA \\\\\n",
    "\\text{Lead } II& : & LL - RA \\\\\n",
    "\\text{Lead } III& : & LL - LA \\\\\n",
    "\\text{Lead } aVR& : &  \\frac{3}{2} (RA - Vw) \\\\\n",
    "\\text{Lead } aVL& : &  \\frac{3}{2} (LA - Vw) \\\\\n",
    "\\text{Lead } aVF& : &  \\frac{3}{2} (LL - Vw)\\\\ \n",
    "\\text{Lead } V1 & : & V1 - Vw \\\\\n",
    "\\text{Lead } V2 & : & V2 - Vw \\\\\n",
    "\\text{Lead } V3 & : & V3 - Vw \\\\\n",
    "\\text{Lead } V4 & : & V4 - Vw \\\\\n",
    "\\text{Lead } V5 & : & V5 - Vw \\\\\n",
    "\\text{Lead } V6 & : & V6 - Vw \\\\\n",
    "\\end{array}\n",
    "\\right.\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cc3bed18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Example of file pair\n",
    "# case = 213\n",
    "# # ECG plot\n",
    "# row = 3 \n",
    "# column = 4\n",
    "# num_timesteps = 500\n",
    "# plt.figure(figsize=(10, 7))\n",
    "# titles = [\"I\", \"II\", \"III\", \"aVR\", \"aVL\", \"aVF\", \"V1\", \"V2\", \"V3\", \"V4\", \"V5\", \"V6\"]\n",
    "# reorder = {1:1,2:5,3:9,4:2,5:6,6:10,7:3,8:7,9:11,10:4,11:8,12:12} # reorder the leads to standard 12-lead ECG display\n",
    "\n",
    "# print('Case {} : {}'.format(case, file_pairs[case][0]))\n",
    "# pECGData = np.load(file_pairs[case][0])\n",
    "# pECGData = get_standard_leads(pECGData)\n",
    "\n",
    "# # create a figure with 12 subplots\n",
    "# for i in range(pECGData.shape[1]):\n",
    "#     plt.subplot(row, column, reorder[i + 1])\n",
    "#     plt.plot(pECGData[0:num_timesteps,i],'r', color='blue', alpha=0.8)\n",
    "#     plt.title(titles[i])\n",
    "#     # plt.plot(visible=True, color='blue', linestyle='-')\n",
    "#     plt.minorticks_on()\n",
    "#     # plt.plot(visible=True, color='blue', linestyle='-', alpha=0.2)\n",
    "#     plt.xlabel('msec')\n",
    "#     plt.ylabel('mV')\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n",
    "# # close\n",
    "# plt.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7346c1bb",
   "metadata": {},
   "source": [
    "### 2.2 Getting the activation map from the transmembrane voltages\n",
    "\n",
    "The funtion `get_activation_map` (in the file `cardiac_ml_tools.py`) is used to obtain the activation map from the transmembrane voltages. It implements the following transformation $A_i = \\text{min}_j(V_{ij})$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ee45c6de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Example of file pair\n",
    "# case = 213\n",
    "# # plt.figure(figsize=(1, 10))\n",
    "# plt.figure(figsize=(15, 2))\n",
    "\n",
    "# print('Case {} : {}'.format(case, file_pairs[case][0]))\n",
    "# VmData = np.load(file_pairs[case][1])\n",
    "\n",
    "# ActTime = get_activation_time(VmData)\n",
    "\n",
    "# # plot the Activation Time array\n",
    "# plt.imshow(ActTime.T, cmap='jet', interpolation='nearest', aspect='auto')\n",
    "# plt.title('Activation Time')\n",
    "# plt.colorbar()\n",
    "# plt.grid(visible=True, which='major', color='#666666', linestyle='-')\n",
    "# plt.minorticks_on()\n",
    "# # not yticks\n",
    "# plt.yticks([])\n",
    "# plt.grid(visible=True, which='minor', color='#999999', linestyle='-', alpha=0.2)\n",
    "# plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c0123209",
   "metadata": {},
   "source": [
    "### 3.3 Learning the mapping from the 12-lead ECG to the activation map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c1b6d72c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # make a plot with the \"pECGData\" -> \"ActTime\"\n",
    "# case = 213\n",
    "\n",
    "# print('Case {} : {}'.format(case, file_pairs[case][0]))\n",
    "# pECGData = np.load(file_pairs[case][0])\n",
    "# pECGData = get_standard_leads(pECGData)\n",
    "\n",
    "# print('Case {} : {}'.format(case, file_pairs[case][0]))\n",
    "# VmData = np.load(file_pairs[case][1])\n",
    "# ActTime = get_activation_time(VmData)\n",
    "\n",
    "# # plot in row the tensors pECGData and ActTime with an arrow pointing to the activation time\n",
    "# row = 1\n",
    "# column = 3\n",
    "# plt.figure(figsize=(20, 5))\n",
    "# plt.subplot(row, column, 1)\n",
    "# # plot pECGData transposed\n",
    "# plt.imshow(pECGData.T, cmap='jet', interpolation='nearest', aspect='auto')\n",
    "# plt.title('pECGData')\n",
    "# plt.subplot(row, column, 2)\n",
    "# # print an arrow\n",
    "# plt.text(0.5, 0.5, '-------->', horizontalalignment='center', verticalalignment='center', fontsize=20)\n",
    "# plt.axis('off')\n",
    "# plt.subplot(row, column, 3)\n",
    "# # plot ActTime\n",
    "# plt.imshow(ActTime, cmap='jet', interpolation='nearest', aspect='auto')\n",
    "# # not xticks\n",
    "# plt.xticks([])\n",
    "# plt.title('ActTime')\n",
    "# plt.show()\n",
    "# plt.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "204d7bd1",
   "metadata": {},
   "source": [
    "**Tricks**\n",
    "\n",
    "As in many machine learning problems, normalization of the data might be helpful or even necessary. Different normalization schemes might be applied."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ffeee68",
   "metadata": {},
   "source": [
    "## CONSTRUCT\n",
    "\n",
    "**Model: 1D CNN**\n",
    "\n",
    "**Approach**\n",
    "\n",
    "We to flatten each 2D sample (12x500) from the ECG data into a 1D row, transforming each sample from a matrix into a long vector. Then, you want to stack all these vectors from over 16,000 samples into a single large dataset where each row represents one sample, fully flattened, resulting in a dataset with dimensions of (16000, 6000) — since 12 x 500 = 6000.\n",
    "\n",
    "Here’s the step-by-step plan to achieve this:\n",
    "\n",
    "1. **Flatten Each Sample**: Each 12x500 matrix will be reshaped into a single row of 6000 elements. This converts the 2D feature set of each sample into a 1D array.\n",
    "\n",
    "2. **Stack All Samples**: After flattening each sample, you'll stack them vertically to create a new dataset where each row corresponds to one of the original 2D samples, now represented as a long 1D vector.\n",
    "\n",
    "3. **Create a Uniform Dataset**: The result will be a large dataset where every sample is consistently formatted in a single row, making it easier to handle in terms of data processing and input into machine learning models.\n",
    "\n",
    "4. **Store or Process This Dataset**: Depending on the final application, this dataset can then be either stored for further use, processed for normalization, or directly used as input for machine learning models, particularly for tasks like clustering, classification, or regression.\n",
    "\n",
    "This approach effectively transforms a complex 2D dataset into a more manageable 1D format, albeit at the expense of increasing the dimensionality of each data point. This can be useful for certain types of analyses or machine learning models that require a flat vector per sample.\n",
    "\n",
    "**Combine Dataset Approach**\n",
    "\n",
    "Given that your full dataset contains over 16,000 samples, here's a graduated approach to determining an initial subset size:\n",
    "\n",
    "- **Initial Proof of Concept**: Start with a very small amount of data, perhaps around **100 to 500 samples**. This size is usually sufficient to ensure that your data loading, processing, and model training pipelines are functioning correctly without excessive computational overhead.\n",
    "\n",
    "- **Preliminary Testing**: Once your initial setup is verified to be working correctly, increase the size to about **1,000 to 2,000 samples**. This provides a more statistically significant dataset to start tuning hyperparameters and testing model performance while still being manageable in terms of computational resources and time.\n",
    "\n",
    "- **Detailed Testing and Validation**: If the model performs well on 1,000 to 2,000 samples, consider using a larger subset, such as **5,000 to 10,000 samples**, to further refine your model and prepare for full-scale training. This step is crucial for understanding how well the model scales with data size and for final adjustments before deploying the model on the entire dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca82414b",
   "metadata": {},
   "source": [
    "\n",
    "### 3.1 Data Processing\n",
    "\n",
    "#### 3.1.1 Combine Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8e32d1dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If file active.npy and ecg.npy are already created, load them\n",
    "if os.path.exists('./combine_dataset/ecg_data.npy') and os.path.exists('./combine_dataset/active_time.npy'):\n",
    "    # ECGData = np.load('./combine_dataset/ecg_data.npy')\n",
    "    # ActTime = np.load('./combine_dataset/active_time.npy')\n",
    "    ECGData = np.load('./combine_dataset/ecg_data_5000.npy')\n",
    "    ActTime = np.load('./combine_dataset/active_time_5000.npy')\n",
    "\n",
    "else:\n",
    "    # file_pairs is a list where each element is a tuple containing the file paths for ECG data and activation time data\n",
    "    num_samples = 16117  # Number of samples to process\n",
    "    num_timesteps = 500  # Each ECG data has 500 timesteps\n",
    "    num_leads = 12  # Standard ECG leads count after processing\n",
    "\n",
    "    # Initialize arrays to store combined data\n",
    "    ECGData = np.zeros((num_samples, num_timesteps * num_leads))  # Flattened array for 12 leads data\n",
    "    ActTime = np.zeros((num_samples, 75))  # Store 75 activation times per sample\n",
    "\n",
    "    # Process each sample\n",
    "    for i in range(num_samples):\n",
    "        # Load ECG data\n",
    "        pECGData = np.load(file_pairs[i][0])\n",
    "        pECGData = get_standard_leads(pECGData)  # Convert to 12 standard leads\n",
    "        ECGData[i, :] = pECGData.flatten()  # Flatten and store in the combined array\n",
    "\n",
    "        # Load activation time data\n",
    "        VmData = np.load(file_pairs[i][1])\n",
    "        ActTime[i, :] = get_activation_time(VmData).flatten()\n",
    "        # ActTime[i, :] = ActTime.flatten()  # Flatten the (75, 1) array to fit into (75,) array\n",
    "\n",
    "    # Create directory if it does not exist\n",
    "    output_dir = './combine_dataset'\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # Save combined datasets to .npy format\n",
    "    np.save(os.path.join(output_dir, 'ecg_data.npy'), ECGData)\n",
    "    np.save(os.path.join(output_dir, 'active_time.npy'), ActTime)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa015579",
   "metadata": {},
   "source": [
    "After combine, check them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0af15993",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ECGData shape: (5000, 6000)\n",
      "ActTime shape: (5000, 75)\n"
     ]
    }
   ],
   "source": [
    "print(\"ECGData shape: {}\".format(ECGData.shape))\n",
    "print(\"ActTime shape: {}\".format(ActTime.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38ad071c",
   "metadata": {},
   "source": [
    "\n",
    "#### 3.1.2 Split Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f4365507",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle indices\n",
    "indices = np.arange(ECGData.shape[0])\n",
    "shuffled_indices = shuffle(indices, random_state=42)\n",
    "\n",
    "# Define the split ratios\n",
    "train_ratio = 0.8  # 80% training\n",
    "val_ratio = 0.1  # 10% validation\n",
    "test_ratio = 0.1  # 10% test\n",
    "\n",
    "# Calculate the split points\n",
    "train_split = int(len(shuffled_indices) * train_ratio)\n",
    "val_split = int(len(shuffled_indices) * (train_ratio + val_ratio))\n",
    "\n",
    "# Split indices into training, validation, and test sets\n",
    "train_indices = shuffled_indices[:train_split]\n",
    "val_indices = shuffled_indices[train_split:val_split]\n",
    "test_indices = shuffled_indices[val_split:]\n",
    "\n",
    "# Use indices to create training, validation, and test data\n",
    "X_train = ECGData[train_indices]\n",
    "y_train = ActTime[train_indices]\n",
    "X_val = ECGData[val_indices]\n",
    "y_val = ActTime[val_indices]\n",
    "X_test = ECGData[test_indices]\n",
    "y_test = ActTime[test_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7d6c8fa2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4000, 6000), (4000, 75), (500, 6000), (500, 75), (500, 6000), (500, 75))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape, X_val.shape, y_val.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "645ee309",
   "metadata": {},
   "source": [
    "### 3.2 Modeling\n",
    "\n",
    "#### 3.2.1 Define the 1D CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "afb591fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Simple1DCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Simple1DCNN, self).__init__()\n",
    "\n",
    "        # convolutional layers -> relu -> convolutional layers -> relu -> \n",
    "        # pooling -> flatten -> fully connected layers\n",
    "        self.conv1 = nn.Conv1d(in_channels=12, out_channels=32, kernel_size=15, padding=12)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.conv2 = nn.Conv1d(in_channels=32, out_channels=64, kernel_size=9, padding=7)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.conv3 = nn.Conv1d(in_channels=64, out_channels=128, kernel_size=3, padding=4)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        # self.conv4 = nn.Conv1d(in_channels=128, out_channels=256, kernel_size=3, padding=2)\n",
    "        # self.relu4 = nn.ReLU()\n",
    "\n",
    "        self.pool = nn.MaxPool1d(3)\n",
    "        self.flat = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(22272, 512)\n",
    "        # self.fc1 = nn.Linear(44544, 512)\n",
    "        self.relu4 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(512, 75)  # Output the activation times\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.relu3(x)\n",
    "        # x = self.conv4(x)\n",
    "        # x = self.relu4(x)\n",
    "\n",
    "        x = self.pool(x)\n",
    "        x = self.flat(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu4(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69359550",
   "metadata": {},
   "source": [
    "#### 3.2.2 Initialize the Model and Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5265ae0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Simple1DCNN()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Configure Loss Function\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb57c215",
   "metadata": {},
   "source": [
    "#### 3.2.3 Prepare & Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c6984c5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 773.3668212890625, Val Loss: 842.2888793945312\n",
      "Epoch 2, Loss: 769.5557250976562, Val Loss: 840.7930297851562\n",
      "Epoch 3, Loss: 769.1624755859375, Val Loss: 840.0393676757812\n",
      "Epoch 4, Loss: 769.1134033203125, Val Loss: 837.4114379882812\n",
      "Epoch 5, Loss: 766.8618774414062, Val Loss: 832.9954833984375\n",
      "Epoch 6, Loss: 762.5126342773438, Val Loss: 829.0236206054688\n",
      "Epoch 7, Loss: 758.276611328125, Val Loss: 827.4286499023438\n",
      "Epoch 8, Loss: 756.1256713867188, Val Loss: 827.7444458007812\n",
      "Epoch 9, Loss: 755.780029296875, Val Loss: 827.53857421875\n",
      "Epoch 10, Loss: 755.0977172851562, Val Loss: 825.08642578125\n",
      "Epoch 11, Loss: 752.5741577148438, Val Loss: 821.1156005859375\n",
      "Epoch 12, Loss: 748.9484252929688, Val Loss: 817.591064453125\n",
      "Epoch 13, Loss: 746.0074462890625, Val Loss: 815.4297485351562\n",
      "Epoch 14, Loss: 744.43798828125, Val Loss: 813.9253540039062\n",
      "Epoch 15, Loss: 743.3558349609375, Val Loss: 811.9937133789062\n",
      "Epoch 16, Loss: 741.5794067382812, Val Loss: 809.465087890625\n",
      "Epoch 17, Loss: 738.912841796875, Val Loss: 807.1118774414062\n",
      "Epoch 18, Loss: 736.1875610351562, Val Loss: 805.5889892578125\n",
      "Epoch 19, Loss: 734.229736328125, Val Loss: 804.5234985351562\n",
      "Epoch 20, Loss: 732.9283447265625, Val Loss: 802.8347778320312\n",
      "Epoch 21, Loss: 731.4453125, Val Loss: 799.9456176757812\n",
      "Epoch 22, Loss: 729.2840576171875, Val Loss: 796.3734130859375\n",
      "Epoch 23, Loss: 726.8305053710938, Val Loss: 793.0267944335938\n",
      "Epoch 24, Loss: 724.7376098632812, Val Loss: 790.239013671875\n",
      "Epoch 25, Loss: 723.0978393554688, Val Loss: 787.6865234375\n",
      "Epoch 26, Loss: 721.4443969726562, Val Loss: 785.0336303710938\n",
      "Epoch 27, Loss: 719.4017333984375, Val Loss: 782.3785400390625\n",
      "Epoch 28, Loss: 717.1107177734375, Val Loss: 780.0307006835938\n",
      "Epoch 29, Loss: 714.9839477539062, Val Loss: 777.9915161132812\n",
      "Epoch 30, Loss: 713.1666870117188, Val Loss: 775.8510131835938\n",
      "Epoch 31, Loss: 711.3846435546875, Val Loss: 773.2582397460938\n",
      "Epoch 32, Loss: 709.342529296875, Val Loss: 770.295166015625\n",
      "Epoch 33, Loss: 707.1041870117188, Val Loss: 767.371826171875\n",
      "Epoch 34, Loss: 704.949462890625, Val Loss: 764.6920166015625\n",
      "Epoch 35, Loss: 702.9568481445312, Val Loss: 762.14453125\n",
      "Epoch 36, Loss: 700.9344482421875, Val Loss: 759.5921020507812\n",
      "Epoch 37, Loss: 698.7097778320312, Val Loss: 757.0673828125\n",
      "Epoch 38, Loss: 696.3434448242188, Val Loss: 754.6387329101562\n",
      "Epoch 39, Loss: 694.01025390625, Val Loss: 752.2138671875\n",
      "Epoch 40, Loss: 691.7398681640625, Val Loss: 749.5475463867188\n",
      "Epoch 41, Loss: 689.3882446289062, Val Loss: 746.4321899414062\n",
      "Epoch 42, Loss: 686.8555297851562, Val Loss: 743.1245727539062\n",
      "Epoch 43, Loss: 684.1900634765625, Val Loss: 739.730224609375\n",
      "Epoch 44, Loss: 681.5120239257812, Val Loss: 736.311767578125\n",
      "Epoch 45, Loss: 678.7866821289062, Val Loss: 732.7922973632812\n",
      "Epoch 46, Loss: 675.9039306640625, Val Loss: 729.185546875\n",
      "Epoch 47, Loss: 672.831787109375, Val Loss: 725.5201416015625\n",
      "Epoch 48, Loss: 669.6409301757812, Val Loss: 721.7381591796875\n",
      "Epoch 49, Loss: 666.3683471679688, Val Loss: 717.709228515625\n",
      "Epoch 50, Loss: 662.954345703125, Val Loss: 713.2660522460938\n",
      "Epoch 51, Loss: 659.2950439453125, Val Loss: 708.5779418945312\n",
      "Epoch 52, Loss: 655.4346923828125, Val Loss: 703.6253051757812\n",
      "Epoch 53, Loss: 651.3688354492188, Val Loss: 698.5390014648438\n",
      "Epoch 54, Loss: 647.107177734375, Val Loss: 693.2929077148438\n",
      "Epoch 55, Loss: 642.51904296875, Val Loss: 687.8630981445312\n",
      "Epoch 56, Loss: 637.64697265625, Val Loss: 682.1676025390625\n",
      "Epoch 57, Loss: 632.4715576171875, Val Loss: 676.1251220703125\n",
      "Epoch 58, Loss: 626.9818725585938, Val Loss: 669.63330078125\n",
      "Epoch 59, Loss: 621.121826171875, Val Loss: 662.7477416992188\n",
      "Epoch 60, Loss: 614.9047241210938, Val Loss: 655.3807983398438\n",
      "Epoch 61, Loss: 608.2913208007812, Val Loss: 647.78857421875\n",
      "Epoch 62, Loss: 601.3755493164062, Val Loss: 639.9248046875\n",
      "Epoch 63, Loss: 594.056640625, Val Loss: 631.8347778320312\n",
      "Epoch 64, Loss: 586.4247436523438, Val Loss: 623.4918212890625\n",
      "Epoch 65, Loss: 578.5292358398438, Val Loss: 614.8401489257812\n",
      "Epoch 66, Loss: 570.4172973632812, Val Loss: 605.92626953125\n",
      "Epoch 67, Loss: 562.1531982421875, Val Loss: 596.87451171875\n",
      "Epoch 68, Loss: 553.8648681640625, Val Loss: 588.0369262695312\n",
      "Epoch 69, Loss: 545.6808471679688, Val Loss: 579.4022216796875\n",
      "Epoch 70, Loss: 537.604736328125, Val Loss: 571.1155395507812\n",
      "Epoch 71, Loss: 529.8414916992188, Val Loss: 563.1435546875\n",
      "Epoch 72, Loss: 522.3624267578125, Val Loss: 555.3975219726562\n",
      "Epoch 73, Loss: 515.1700439453125, Val Loss: 547.7036743164062\n",
      "Epoch 74, Loss: 508.12896728515625, Val Loss: 539.64208984375\n",
      "Epoch 75, Loss: 501.0886535644531, Val Loss: 531.3167114257812\n",
      "Epoch 76, Loss: 493.9337463378906, Val Loss: 522.6360473632812\n",
      "Epoch 77, Loss: 486.4852294921875, Val Loss: 513.5343017578125\n",
      "Epoch 78, Loss: 478.7851257324219, Val Loss: 504.09674072265625\n",
      "Epoch 79, Loss: 470.950927734375, Val Loss: 494.5243835449219\n",
      "Epoch 80, Loss: 463.1481628417969, Val Loss: 485.1349182128906\n",
      "Epoch 81, Loss: 455.53033447265625, Val Loss: 476.2805480957031\n",
      "Epoch 82, Loss: 448.26580810546875, Val Loss: 468.1739807128906\n",
      "Epoch 83, Loss: 441.5174865722656, Val Loss: 460.8021240234375\n",
      "Epoch 84, Loss: 435.3206787109375, Val Loss: 454.1169128417969\n",
      "Epoch 85, Loss: 429.7419738769531, Val Loss: 448.0303039550781\n",
      "Epoch 86, Loss: 424.699462890625, Val Loss: 442.5825500488281\n",
      "Epoch 87, Loss: 420.18084716796875, Val Loss: 437.7019348144531\n",
      "Epoch 88, Loss: 416.0722961425781, Val Loss: 433.24310302734375\n",
      "Epoch 89, Loss: 412.2995300292969, Val Loss: 429.09259033203125\n",
      "Epoch 90, Loss: 408.8116149902344, Val Loss: 425.2165832519531\n",
      "Epoch 91, Loss: 405.5556335449219, Val Loss: 421.57244873046875\n",
      "Epoch 92, Loss: 402.47509765625, Val Loss: 418.12371826171875\n",
      "Epoch 93, Loss: 399.5242614746094, Val Loss: 414.7930908203125\n",
      "Epoch 94, Loss: 396.6317138671875, Val Loss: 411.5283508300781\n",
      "Epoch 95, Loss: 393.7921142578125, Val Loss: 408.3636169433594\n",
      "Epoch 96, Loss: 391.0343322753906, Val Loss: 405.174072265625\n",
      "Epoch 97, Loss: 388.2923278808594, Val Loss: 401.8877868652344\n",
      "Epoch 98, Loss: 385.5585632324219, Val Loss: 398.54364013671875\n",
      "Epoch 99, Loss: 382.8489685058594, Val Loss: 395.2575988769531\n",
      "Epoch 100, Loss: 380.22198486328125, Val Loss: 392.1424560546875\n",
      "Epoch 101, Loss: 377.7319641113281, Val Loss: 389.2537536621094\n",
      "Epoch 102, Loss: 375.419677734375, Val Loss: 386.62445068359375\n",
      "Epoch 103, Loss: 373.2900695800781, Val Loss: 384.2143249511719\n",
      "Epoch 104, Loss: 371.3232116699219, Val Loss: 381.9312438964844\n",
      "Epoch 105, Loss: 369.4736022949219, Val Loss: 379.7297058105469\n",
      "Epoch 106, Loss: 367.7005920410156, Val Loss: 377.61419677734375\n",
      "Epoch 107, Loss: 365.9827880859375, Val Loss: 375.5625305175781\n",
      "Epoch 108, Loss: 364.3082275390625, Val Loss: 373.5477600097656\n",
      "Epoch 109, Loss: 362.6838073730469, Val Loss: 371.6118469238281\n",
      "Epoch 110, Loss: 361.1177062988281, Val Loss: 369.7549743652344\n",
      "Epoch 111, Loss: 359.6299133300781, Val Loss: 367.85760498046875\n",
      "Epoch 112, Loss: 358.22052001953125, Val Loss: 366.0373840332031\n",
      "Epoch 113, Loss: 356.89678955078125, Val Loss: 364.322509765625\n",
      "Epoch 114, Loss: 355.6460266113281, Val Loss: 362.6517639160156\n",
      "Epoch 115, Loss: 354.4459533691406, Val Loss: 361.0877990722656\n",
      "Epoch 116, Loss: 353.2788391113281, Val Loss: 359.53582763671875\n",
      "Epoch 117, Loss: 352.1374206542969, Val Loss: 357.96075439453125\n",
      "Epoch 118, Loss: 350.9873046875, Val Loss: 356.4417419433594\n",
      "Epoch 119, Loss: 349.84930419921875, Val Loss: 354.895263671875\n",
      "Epoch 120, Loss: 348.7191162109375, Val Loss: 353.5133972167969\n",
      "Epoch 121, Loss: 347.61163330078125, Val Loss: 352.10430908203125\n",
      "Epoch 122, Loss: 346.5085144042969, Val Loss: 350.835693359375\n",
      "Epoch 123, Loss: 345.44305419921875, Val Loss: 349.68072509765625\n",
      "Epoch 124, Loss: 344.4088134765625, Val Loss: 348.4842224121094\n",
      "Epoch 125, Loss: 343.3924865722656, Val Loss: 347.4114685058594\n",
      "Epoch 126, Loss: 342.4006042480469, Val Loss: 346.26495361328125\n",
      "Epoch 127, Loss: 341.42596435546875, Val Loss: 345.2883605957031\n",
      "Epoch 128, Loss: 340.4655456542969, Val Loss: 344.2091979980469\n",
      "Epoch 129, Loss: 339.51385498046875, Val Loss: 343.2854309082031\n",
      "Epoch 130, Loss: 338.5736999511719, Val Loss: 342.1997985839844\n",
      "Epoch 131, Loss: 337.64105224609375, Val Loss: 341.2613830566406\n",
      "Epoch 132, Loss: 336.7169189453125, Val Loss: 340.1298522949219\n",
      "Epoch 133, Loss: 335.8078308105469, Val Loss: 339.19659423828125\n",
      "Epoch 134, Loss: 334.9181213378906, Val Loss: 338.0846252441406\n",
      "Epoch 135, Loss: 334.054931640625, Val Loss: 337.30377197265625\n",
      "Epoch 136, Loss: 333.2371826171875, Val Loss: 336.2660827636719\n",
      "Epoch 137, Loss: 332.4720764160156, Val Loss: 335.66265869140625\n",
      "Epoch 138, Loss: 331.7639465332031, Val Loss: 334.56951904296875\n",
      "Epoch 139, Loss: 331.0349426269531, Val Loss: 333.8724060058594\n",
      "Epoch 140, Loss: 330.18585205078125, Val Loss: 332.4856872558594\n",
      "Epoch 141, Loss: 329.16351318359375, Val Loss: 331.4754638671875\n",
      "Epoch 142, Loss: 328.0623474121094, Val Loss: 330.28643798828125\n",
      "Epoch 143, Loss: 327.0740966796875, Val Loss: 329.39642333984375\n",
      "Epoch 144, Loss: 326.27685546875, Val Loss: 328.7577209472656\n",
      "Epoch 145, Loss: 325.6264953613281, Val Loss: 327.8916931152344\n",
      "Epoch 146, Loss: 325.04864501953125, Val Loss: 327.4726257324219\n",
      "Epoch 147, Loss: 324.4624938964844, Val Loss: 326.474365234375\n",
      "Epoch 148, Loss: 323.82659912109375, Val Loss: 325.9515075683594\n",
      "Epoch 149, Loss: 323.074462890625, Val Loss: 324.76959228515625\n",
      "Epoch 150, Loss: 322.224365234375, Val Loss: 324.0066833496094\n",
      "Epoch 151, Loss: 321.314697265625, Val Loss: 322.9251403808594\n",
      "Epoch 152, Loss: 320.4460754394531, Val Loss: 322.186279296875\n",
      "Epoch 153, Loss: 319.6724853515625, Val Loss: 321.39990234375\n",
      "Epoch 154, Loss: 318.9863586425781, Val Loss: 320.69390869140625\n",
      "Epoch 155, Loss: 318.36981201171875, Val Loss: 320.1583557128906\n",
      "Epoch 156, Loss: 317.81256103515625, Val Loss: 319.51129150390625\n",
      "Epoch 157, Loss: 317.3379821777344, Val Loss: 319.2926330566406\n",
      "Epoch 158, Loss: 317.006591796875, Val Loss: 318.951416015625\n",
      "Epoch 159, Loss: 316.9397277832031, Val Loss: 319.5508117675781\n",
      "Epoch 160, Loss: 317.21893310546875, Val Loss: 319.656005859375\n",
      "Epoch 161, Loss: 317.73480224609375, Val Loss: 319.8376159667969\n",
      "Epoch 162, Loss: 317.4425354003906, Val Loss: 317.73370361328125\n",
      "Epoch 163, Loss: 315.8640441894531, Val Loss: 315.75408935546875\n",
      "Epoch 164, Loss: 313.6671447753906, Val Loss: 314.82574462890625\n",
      "Epoch 165, Loss: 312.84075927734375, Val Loss: 315.20928955078125\n",
      "Epoch 166, Loss: 313.40875244140625, Val Loss: 315.88189697265625\n",
      "Epoch 167, Loss: 313.6978454589844, Val Loss: 314.48785400390625\n",
      "Epoch 168, Loss: 312.7469482421875, Val Loss: 313.0990295410156\n",
      "Epoch 169, Loss: 311.212646484375, Val Loss: 312.3754577636719\n",
      "Epoch 170, Loss: 310.59942626953125, Val Loss: 312.4822082519531\n",
      "Epoch 171, Loss: 310.89794921875, Val Loss: 312.7678527832031\n",
      "Epoch 172, Loss: 310.9395446777344, Val Loss: 311.6454162597656\n",
      "Epoch 173, Loss: 310.1870422363281, Val Loss: 310.6765441894531\n",
      "Epoch 174, Loss: 309.0899353027344, Val Loss: 310.004638671875\n",
      "Epoch 175, Loss: 308.505615234375, Val Loss: 309.88641357421875\n",
      "Epoch 176, Loss: 308.5124816894531, Val Loss: 310.2000427246094\n",
      "Epoch 177, Loss: 308.61956787109375, Val Loss: 309.7046813964844\n",
      "Epoch 178, Loss: 308.385009765625, Val Loss: 309.2357482910156\n",
      "Epoch 179, Loss: 307.6637878417969, Val Loss: 308.1722106933594\n",
      "Epoch 180, Loss: 306.84820556640625, Val Loss: 307.6357727050781\n",
      "Epoch 181, Loss: 306.2720947265625, Val Loss: 307.42205810546875\n",
      "Epoch 182, Loss: 306.0443115234375, Val Loss: 307.1806945800781\n",
      "Epoch 183, Loss: 305.96990966796875, Val Loss: 307.2554016113281\n",
      "Epoch 184, Loss: 305.8367919921875, Val Loss: 306.7103576660156\n",
      "Epoch 185, Loss: 305.54681396484375, Val Loss: 306.40863037109375\n",
      "Epoch 186, Loss: 305.07391357421875, Val Loss: 305.63153076171875\n",
      "Epoch 187, Loss: 304.5249328613281, Val Loss: 305.1955261230469\n",
      "Epoch 188, Loss: 303.99755859375, Val Loss: 304.68548583984375\n",
      "Epoch 189, Loss: 303.56982421875, Val Loss: 304.3515930175781\n",
      "Epoch 190, Loss: 303.246826171875, Val Loss: 304.1665954589844\n",
      "Epoch 191, Loss: 303.00189208984375, Val Loss: 303.85406494140625\n",
      "Epoch 192, Loss: 302.8139343261719, Val Loss: 303.86187744140625\n",
      "Epoch 193, Loss: 302.6759033203125, Val Loss: 303.5462646484375\n",
      "Epoch 194, Loss: 302.6171875, Val Loss: 303.88641357421875\n",
      "Epoch 195, Loss: 302.6670837402344, Val Loss: 303.7322082519531\n",
      "Epoch 196, Loss: 302.89031982421875, Val Loss: 304.5376892089844\n",
      "Epoch 197, Loss: 303.2377014160156, Val Loss: 304.5036315917969\n",
      "Epoch 198, Loss: 303.6780090332031, Val Loss: 305.04986572265625\n",
      "Epoch 199, Loss: 303.6207580566406, Val Loss: 303.7640075683594\n",
      "Epoch 200, Loss: 302.9263916015625, Val Loss: 302.6557312011719\n"
     ]
    }
   ],
   "source": [
    "# Prepare\n",
    "X_train_tensor = torch.tensor(X_train.reshape(4000, 12, 500), dtype=torch.float32)  # Add channel dimension\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32)\n",
    "X_val_tensor = torch.tensor(X_val.reshape(500, 12, 500), dtype=torch.float32)  # Add channel dimension\n",
    "y_val_tensor = torch.tensor(y_val, dtype=torch.float32)\n",
    "\n",
    "# Train\n",
    "num_epochs = 200  # or however many you deem necessary\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    output = model(X_train_tensor)\n",
    "    loss = criterion(output, y_train_tensor)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    # Evaluate on validation set\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        val_output = model(X_val_tensor)\n",
    "        val_loss = criterion(val_output, y_val_tensor)\n",
    "    \n",
    "    print(f'Epoch {epoch+1}, Loss: {loss.item()}, Val Loss: {val_loss.item()}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "083c629e",
   "metadata": {},
   "source": [
    "### 3.3 Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c2563963",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Evaluate model\n",
    "# model.eval()\n",
    "\n",
    "# # Prepare test data\n",
    "# X_test_tensor = torch.tensor(X_test.reshape(4836, 12, 500), dtype=torch.float32)  # Add channel dimension\n",
    "# y_test_tensor = torch.tensor(y_test, dtype=torch.float32)\n",
    "\n",
    "# # Predict\n",
    "# with torch.no_grad():\n",
    "#     y_pred = model(X_test_tensor)\n",
    "\n",
    "# # Calculate loss\n",
    "# test_loss = criterion(y_pred, y_test_tensor)\n",
    "# print(f'Test Loss: {test_loss.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8badd5a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "# torch.save(model.state_dict(), '1dcnn.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "nbdime-conflicts": {
   "local_diff": [
    {
     "key": "kernelspec",
     "op": "add",
     "value": {
      "display_name": "PyTorch_Kernel",
      "language": "python",
      "name": "python3"
     }
    }
   ],
   "remote_diff": [
    {
     "key": "kernelspec",
     "op": "add",
     "value": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
     }
    }
   ]
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
